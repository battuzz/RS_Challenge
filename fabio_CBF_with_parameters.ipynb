{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import *\n",
    "from scipy.sparse.linalg import svds\n",
    "import math\n",
    "\n",
    "from recsys.preprocess import *\n",
    "\n",
    "import functools\n",
    "\n",
    "#from recsys.utility import *\n",
    "\n",
    "#RANDOM_STATE = 666\n",
    "\n",
    "#np.random.seed(RANDOM_STATE)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(train, test_size=0.3, min_playlist_tracks=7):\n",
    "    \"\"\"\n",
    "        Standard train_test_split, no modifications.\n",
    "    \"\"\"\n",
    "    playlists = train[train.playlist_id.isin(target_playlists_original.playlist_id)].groupby('playlist_id').count()\n",
    "\n",
    "    # Only playlists with at least \"min_playlist_tracks\" tracks are considered.\n",
    "    # If \"min_playlists_tracks\" = 7, then 28311 out of 45649 playlists in \"train\" are considered.\n",
    "    to_choose_playlists = playlists[playlists['track_id'] >= min_playlist_tracks].index.values\n",
    "\n",
    "\n",
    "    # Among these playlists, \"test_size * len(to_choose_playlists)\" distinct playlists are chosen for testing.\n",
    "    # If \"test_size\" = 0.3, then 8493 playlists are chosen for testing.\n",
    "    # It's a numpy array that contains playlis_ids.\n",
    "    target_playlists = np.random.choice(to_choose_playlists, replace=False, size=int(test_size * len(to_choose_playlists)))\n",
    "\n",
    "    target_tracks = np.array([])\n",
    "    indexes = np.array([])\n",
    "    for p in target_playlists:\n",
    "        # Choose 5 random tracks of such playlist: since we selected playlists with at least \"min_playlist_tracks\"\n",
    "        # tracks, if \"min_playlist_tracks\" is at least 5, we are sure to find them.\n",
    "        selected_df = train[train['playlist_id'] == p].sample(5)\n",
    "\n",
    "        selected_tracks = selected_df['track_id'].values\n",
    "        target_tracks = np.union1d(target_tracks, selected_tracks)\n",
    "        indexes = np.union1d(indexes, selected_df.index.values)\n",
    "\n",
    "    test = train.loc[indexes].copy()\n",
    "    train = train.drop(indexes)\n",
    "\n",
    "    return train, test, pd.DataFrame(target_playlists, columns=['playlist_id']), pd.DataFrame(target_tracks, columns=['track_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def dot_with_top(m1, m2, def_rows_g, top=-1, row_group=1, similarity=\"dot\", shrinkage=0.000001, alpha=1):\n",
    "    \"\"\"\n",
    "        Produces the product between matrices m1 and m2.\n",
    "        Possible similarities: \"dot\", \"cosine\". By default it goes on \"dot\".\n",
    "        NB: Shrinkage is not implemented...\n",
    "        Code taken from\n",
    "            https://stackoverflow.com/questions/29647326/sparse-matrix-dot-product-keeping-only-n-max-values-per-result-row\n",
    "            and optimized for smart dot products.\n",
    "    \"\"\"\n",
    "    m2_transposed = m2.transpose()\n",
    "    \n",
    "    l2 = m2.sum(axis=0) #Â by cols\n",
    "    \n",
    "    if top > 0:\n",
    "        final_rows = []\n",
    "        row_id = 0\n",
    "        while row_id < m1.shape[0]:\n",
    "            last_row = row_id + row_group if row_id + row_group <= m1.shape[0] else m1.shape[0]\n",
    "            rows = m1[row_id:last_row]\n",
    "            if rows.count_nonzero() > 0:\n",
    "                if similarity == \"cosine-old\":\n",
    "                    res_rows = cosine_similarity(rows, m2_transposed, dense_output=False)\n",
    "                elif similarity == \"cosine\":\n",
    "                    res_rows = csr_matrix((np.dot(rows,m2) / (np.sqrt(rows.sum(axis=1)) * np.sqrt(l2) + shrinkage)))\n",
    "                elif similarity == \"cosine-asym\":\n",
    "                    res_rows = csr_matrix((np.dot(rows,m2) / (np.power(rows.sum(axis=1),alpha) * np.power(m2.sum(axis=0),(1-alpha)) + shrinkage)))\n",
    "                elif similarity == \"dot-old\":\n",
    "                    res_rows = rows.dot(m2)\n",
    "                else:\n",
    "                    res_rows = (np.dot(rows,m2) + shrinkage).toarray()\n",
    "                if res_rows.count_nonzero() > 0:\n",
    "                    for res_row in res_rows:\n",
    "                        if res_row.nnz > top:\n",
    "                            args_ids = np.argsort(res_row.data)[-top:]\n",
    "                            data = res_row.data[args_ids]\n",
    "                            cols = res_row.indices[args_ids]\n",
    "                            final_rows.append(csr_matrix((data, (np.zeros(top), cols)), shape=res_row.shape))\n",
    "                        else:\n",
    "                            args_ids = np.argsort(res_row.data)[-top:]\n",
    "                            data = res_row.data[args_ids]\n",
    "                            cols = res_row.indices[args_ids]\n",
    "                            final_rows.append(csr_matrix((data, (np.zeros(len(args_ids)), cols)), shape=res_row.shape))\n",
    "                            #print(\"Less than top: {0}\".format(len(args_ids)))\n",
    "                            #final_rows.append(def_rows_g[0])\n",
    "                else:\n",
    "                    print(\"Add empty 2\")\n",
    "                    for res_row in res_rows:\n",
    "                        final_rows.append(def_rows_g[0])\n",
    "            else:\n",
    "                print(\"Add empty 3\")\n",
    "                final_rows.append(def_rows_g)\n",
    "            row_id += row_group\n",
    "            if row_id % row_group == 0:\n",
    "                print(row_id)\n",
    "        return scipy.sparse.vstack(final_rows, 'csr')\n",
    "    return m1.dot(m2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii_1_predictor ....... 0.056192049664564016\n",
      "ii_2_predictor ....... 0.05717632922799658\n",
      "ii_3_predictor ....... 0.05539551416841893\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ttracks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-428-01db3aec8a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURM_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-367-f4b3e5424a2b>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(predictor, original_urm, target_playlists, target_tracks, compute_MAP, test)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nope\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_urm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_good\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_good\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_prediction_matrix_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_to_tracks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_to_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tracks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-424-323c223f7e64>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, original_urm, target_playlists, target_tracks, row_group, keep_best, normalize_columns, compute_MAP, test_good)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURM_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_playlists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_good\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_good\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-424-323c223f7e64>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, original_urm, target_playlists, target_tracks, row_group, keep_best, normalize_columns, compute_MAP, test_good)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mpl_tracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_tracks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpl_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mbest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# keep only tracks that are in target_tracks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mbest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_tracks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove tracks that are already in the playlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbest_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkeep_best\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# keep only the best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ttracks' is not defined"
     ]
    }
   ],
   "source": [
    "make_predictions(final_predictor, URM_normalize, target_playlists, target_tracks, compute_MAP=True, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_num_to_id(df, row_num, column = 'track_id'):\n",
    "    \"\"\" df must have a 'track_id' column \"\"\"\n",
    "    return df.iloc[row_num][column]\n",
    "\n",
    "def from_id_to_num(df, tr_id, column='track_id'):\n",
    "    \"\"\" df must have a 'track_id' column \"\"\"\n",
    "    return np.where(df[column].values == tr_id)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_final.csv', delimiter='\\t')\n",
    "playlists = pd.read_csv('data/playlists_final.csv', delimiter='\\t')\n",
    "target_playlists = pd.read_csv('data/target_playlists.csv', delimiter='\\t')\n",
    "target_tracks = pd.read_csv('data/target_tracks.csv', delimiter = '\\t')\n",
    "tracks = pd.read_csv('data/tracks_final.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We load them just to compare the ones for testing with the original ones.\n",
    "# NB: we shouldn't use them in training!\n",
    "train_original = pd.read_csv('data/train_final.csv', delimiter='\\t')\n",
    "target_playlists_original = pd.read_csv('data/target_playlists.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040522, 10000, 32195)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(target_playlists), len(target_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test, target_playlists, target_tracks = train_test_split(train, test_size=1, min_playlist_tracks=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007232, 33290, 6658, 23868)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(target_playlists), len(target_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Almost all of these were taken from one of your notebook, so you probably understand them\n",
    "tracks['track_id_tmp'] = tracks['track_id']\n",
    "\n",
    "tracks['track_id'] = tracks.index\n",
    "\n",
    "playlists['playlist_id_tmp'] = playlists['playlist_id']\n",
    "playlists['playlist_id'] = playlists.index\n",
    "\n",
    "train['playlist_id_tmp'] = train['playlist_id']\n",
    "train['track_id_tmp'] = train['track_id']\n",
    "\n",
    "track_to_num = pd.Series(tracks.index)\n",
    "track_to_num.index = tracks['track_id_tmp']\n",
    "\n",
    "playlist_to_num = pd.Series(playlists.index)\n",
    "playlist_to_num.index = playlists['playlist_id_tmp']\n",
    "\n",
    "num_to_tracks = pd.Series(tracks['track_id_tmp'])\n",
    "\n",
    "train['track_id'] = train['track_id'].apply(lambda x : track_to_num[x])\n",
    "train['playlist_id'] = train['playlist_id'].apply(lambda x : playlist_to_num[x])\n",
    "\n",
    "tracks.tags = tracks.tags.apply(lambda s: np.array(eval(s), dtype=int))\n",
    "\n",
    "playlists.title = playlists.title.apply(lambda s: np.array(eval(s), dtype=int))\n",
    "\n",
    "target_playlists['playlist_id_tmp'] = target_playlists['playlist_id']\n",
    "target_playlists['playlist_id'] = target_playlists['playlist_id'].apply(lambda x : playlist_to_num[x])\n",
    "\n",
    "target_tracks['track_id_tmp'] = target_tracks['track_id']\n",
    "target_tracks['track_id'] = target_tracks['track_id'].apply(lambda x : track_to_num[x])\n",
    "\n",
    "# Create a dataframe that maps a playlist to the set of its tracks\n",
    "playlist_tracks = pd.DataFrame(train['playlist_id'].drop_duplicates())\n",
    "playlist_tracks.index = train['playlist_id'].unique()\n",
    "playlist_tracks['track_ids'] = train.groupby('playlist_id').apply(lambda x : x['track_id'].values)\n",
    "playlist_tracks = playlist_tracks.sort_values('playlist_id')\n",
    "\n",
    "# Create a dataframe that maps a track to the set of the playlists it appears into\n",
    "track_playlists = pd.DataFrame(train['track_id'].drop_duplicates())\n",
    "track_playlists.index = train['track_id'].unique()\n",
    "track_playlists['playlist_ids'] = train.groupby('track_id').apply(lambda x : x['playlist_id'].values)\n",
    "track_playlists = track_playlists.sort_values('track_id')\n",
    "\n",
    "# Substitute each bad album (i.e. an illformed album such as -1, None, etc) with the 0 album\n",
    "bad_albums = 0\n",
    "def transform_album_1(alb):\n",
    "    global bad_albums\n",
    "    ar = eval(alb)\n",
    "    if len(ar) == 0 or (len(ar) > 0 and (ar[0] == None or ar[0] == -1)):\n",
    "        ar = [0]\n",
    "        bad_albums += 1\n",
    "    return ar[0]\n",
    "\n",
    "tracks.album = tracks.album.apply(lambda alb: transform_album_1(alb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover albums\n",
    "Choose one of the following:<br>\n",
    "1 - fill with most similar albums according to the URM<br>\n",
    "2 - fill with brand new albums "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill with most similar albums according to the URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_UAM_album(tracks, playlist_tracks, target_playlists, norm=\"no\", OKAPI_K=1.7, OKAPI_B=0.75):\n",
    "    \"\"\"\n",
    "        Possible norms are \"no\", \"idf\", okapi\". Default to \"no\".\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_albums = tracks.album.unique()\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    UAM_album = lil_matrix((max(playlists.playlist_id)+1, max(unique_albums)+1))\n",
    "    UAM_album_no_norm = lil_matrix((max(playlists.playlist_id)+1, max(unique_albums)+1))\n",
    "    album_to_playlists = {}\n",
    "    \n",
    "    for row in playlist_tracks.itertuples():\n",
    "        pl_id = row.playlist_id\n",
    "        for tr_id in row.track_ids:\n",
    "            alb = tracks.loc[tr_id].album\n",
    "            UAM_album[pl_id,alb] += 1\n",
    "            UAM_album_no_norm[pl_id,alb] += 1\n",
    "            if alb not in album_to_playlists:\n",
    "                album_to_playlists[alb] = [pl_id]\n",
    "            else:\n",
    "                album_to_playlists[alb].append(pl_id)\n",
    "                \n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    album_to_val = {}\n",
    "    if norm == \"okapi\" or norm == \"idf\" or norm == \"tf\":\n",
    "        avg_document_length = functools.reduce(lambda acc,tr_ids: acc + len(tr_ids), playlist_tracks.track_ids, 0) / len(playlist_tracks)\n",
    "        N = len(playlist_tracks)\n",
    "        \n",
    "        i = 0\n",
    "\n",
    "        for row in playlist_tracks.itertuples():\n",
    "            pl_id = row.playlist_id\n",
    "            albums = UAM_album.rows[pl_id]\n",
    "            data = UAM_album.data[pl_id]\n",
    "            for album in albums:\n",
    "                fq = UAM_album[pl_id,album]\n",
    "                nq = len(album_to_playlists[album])\n",
    "                idf = math.log(500/(nq + 0.5))\n",
    "                \n",
    "                if album not in album_to_val:\n",
    "                    album_to_val[album] = idf\n",
    "                    \n",
    "                if norm == \"idf\":\n",
    "                    UAM_album[pl_id,album] = idf\n",
    "                elif norm == \"okapi\":\n",
    "                    UAM_album[pl_id,album] = idf*(fq*(OKAPI_K+1))/(fq + OKAPI_K*(1 - OKAPI_B + OKAPI_B * sum(data) / avg_document_length))\n",
    "                elif norm == \"tf\":\n",
    "                    UAM_album[pl_id,album] = (fq*(OKAPI_K+1))/(fq + OKAPI_K*(1 - OKAPI_B + OKAPI_B * sum(data) / avg_document_length))\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "    \n",
    "    return UAM_album, UAM_album_no_norm, album_to_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Substitute each album with the most similar album according to playlist frequencies\n",
    "UAM_album, UAM_album_no_norm, album_to_val = get_UAM_album(tracks, playlist_tracks, target_playlists, norm=\"idf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks[\"album_corrected\"] = tracks[\"album\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform_album_sim(tr_id):\n",
    "    tot = np.zeros((1,max(tracks.album)+1))[0]\n",
    "    for pl_id in track_playlists.loc[tr_id].playlist_ids:\n",
    "        ar = UAM_album_no_norm[pl_id].toarray()[0]\n",
    "        tot += np.log(ar + 1)  \n",
    "        #tot += ar.clip(max=1)\n",
    "    if tot.max() != 0:\n",
    "        best_1 = tot.argmax()\n",
    "        best_2 = tot.argpartition(len(tot)-2)[-2]\n",
    "        if best_1 == 0:\n",
    "            return best_2\n",
    "    return 0\n",
    "\n",
    "corrected_albums = 0\n",
    "for row in tracks[tracks.track_id.isin(track_playlists.track_id)].itertuples():\n",
    "    if row.album_corrected == 0:\n",
    "        new_album = transform_album_sim(row.track_id)\n",
    "        if new_album != 0:\n",
    "            tracks.set_value(row.track_id, \"album_corrected\", new_album)\n",
    "            corrected_albums += 1\n",
    "            if corrected_albums % 100 == 0:\n",
    "                print(corrected_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_albums, corrected_albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tracks[tracks.album == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill with brand new albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Substitute each 0 album with a brand new album\n",
    "def transform_album_2(alb):\n",
    "    global next_album_id\n",
    "    if alb == 0:\n",
    "        alb = next_album_id\n",
    "        next_album_id += 1\n",
    "    return alb\n",
    "last_album = tracks.album.max()\n",
    "next_album_id = last_album + 1\n",
    "tracks.album = tracks.album.apply(lambda alb: transform_album_2(alb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tracks[tracks.album == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover tags according to URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks[\"tags_corrected\"] = tracks[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count distinct tags\n",
    "tag_tracks = {}\n",
    "for row in tracks.itertuples():\n",
    "    for tag in row.tags:\n",
    "        if tag in tag_tracks:\n",
    "            tag_tracks[tag].append(row.track_id)\n",
    "        else:\n",
    "            tag_tracks[tag] = [row.track_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Tag Matrix UTM\n",
    "def get_UTM(tracks, playlist_tracks, tag_tracks, norm=\"no\", OKAPI_K=1.7, OKAPI_B=0.75, best_tag=False):\n",
    "    \"\"\"\n",
    "        Possible norm are \"no\", \"okapi\", \"idf\", \"tf\". Default to \"no\".\n",
    "    \"\"\"\n",
    "    \n",
    "    if best_tag:\n",
    "        unique_tags = list(best_tag_tracks.keys())\n",
    "    else:\n",
    "        unique_tags = list(tag_tracks.keys())\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    UTM = lil_matrix((max(playlists.playlist_id)+1, max(unique_tags)+1))\n",
    "    UTM_no_norm = lil_matrix((max(playlists.playlist_id)+1, max(unique_tags)+1))\n",
    "    \n",
    "    for row in playlist_tracks.itertuples():\n",
    "        pl_id = row.playlist_id\n",
    "        for tr_id in row.track_ids:\n",
    "            tr_row = tracks.loc[tr_id]\n",
    "            if best_tag:\n",
    "                UTM[pl_id,tr_row.best_tag] += 1\n",
    "                UTM_no_norm[pl_id,tr_row.best_tag] += 1\n",
    "            else:\n",
    "                for tag in tr_row.tags:\n",
    "                    UTM[pl_id,tag] += 1\n",
    "                    UTM_no_norm[pl_id,tag] += 1\n",
    "                \n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    if norm == \"okapi\" or norm == \"idf\" or norm == \"tf\":\n",
    "        avg_document_length = sum(list(map(lambda l: sum(l), UTM.data)))/len(UTM.data)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for row in playlist_tracks.itertuples():\n",
    "            pl_id = row.playlist_id\n",
    "            tags = UTM.rows[pl_id]\n",
    "            data = UTM.data[pl_id]\n",
    "            for tag in tags:\n",
    "                fq = UTM[pl_id,tag]\n",
    "                if best_tag:\n",
    "                    nq = len(best_tag_tracks[tag])\n",
    "                else:\n",
    "                    nq = len(tag_tracks[tag])\n",
    "                idf = math.log(28000/(nq + 0.5))\n",
    "                \n",
    "                if norm == \"idf\":\n",
    "                    UTM[pl_id,tag] = idf\n",
    "                elif norm == \"okapi\":\n",
    "                    UTM[pl_id,tag] = idf*(fq*(OKAPI_K+1))/(fq + OKAPI_K*(1 - OKAPI_B + OKAPI_B * sum(data) / avg_document_length))\n",
    "                elif norm == \"tf\":\n",
    "                    UTM[pl_id,tag] = (fq*(OKAPI_K+1))/(fq + OKAPI_K*(1 - OKAPI_B + OKAPI_B * sum(data) / avg_document_length))\n",
    "                    \n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "    \n",
    "    return UTM, UTM_no_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UTM, UTM_no_norm = get_UTM(tracks, playlist_tracks, tag_tracks, norm=\"okapi\", best_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tags_sim(tr_id):\n",
    "    tot = csr_matrix((1,max(tag_tracks)+1))\n",
    "    tr_row = track_playlists.loc[tr_id]\n",
    "    for pl_id in tr_row.playlist_ids:\n",
    "        tot += UTM[pl_id]\n",
    "    tot = tot.toarray()[0]\n",
    "    return tot.argsort()[::-1][0:5]\n",
    "    \n",
    "\n",
    "corrected_tags = 0\n",
    "for row in tracks[tracks.track_id.isin(track_playlists.track_id)].itertuples():\n",
    "    if len(row.tags) == 0:\n",
    "        new_tags = get_tags_sim(row.track_id)\n",
    "        tracks.set_value(row.track_id, \"tags\", new_tags)\n",
    "        \n",
    "        corrected_tags += 1\n",
    "        if corrected_tags % 100 == 0:\n",
    "            print(corrected_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-item similarity using only URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(gamma):\n",
    "    if gamma < 0:\n",
    "        return 1 - 1/(1 + math.exp(gamma))\n",
    "    else:\n",
    "        return 1/(1 + math.exp(-gamma))\n",
    "\n",
    "# User Rating Matrix URM\n",
    "def get_URM(tracks, playlists, playlist_tracks, track_playlists, norm=\"no\", pow_base=500, pow_exp=0.15):\n",
    "    \"\"\"\n",
    "        possible normalizations: \"no\", \"idf\", \"sqrt\", \"pow\", \"atan\".\n",
    "        Default \"no\".\n",
    "    \"\"\"\n",
    "    URM = lil_matrix((len(playlists), len(tracks)))\n",
    "    num_playlists = len(playlist_tracks)\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for row in track_playlists.itertuples():\n",
    "        track_id = row.track_id\n",
    "        nq = len(row.playlist_ids)\n",
    "        for pl_id in row.playlist_ids:\n",
    "            if norm == \"idf\":\n",
    "                URM[pl_id,track_id] = math.log((500)/nq)\n",
    "            elif norm == \"sqrt\":\n",
    "                URM[pl_id,track_id] = math.sqrt((500)/nq)\n",
    "            elif norm == \"pow\":\n",
    "                URM[pl_id,track_id] = math.pow((pow_base)/nq, pow_exp)\n",
    "            elif norm == \"atan\":\n",
    "                URM[pl_id,track_id] = 3 + 1*math.atan(-0.1*nq + 1)\n",
    "            else:\n",
    "                URM[pl_id,track_id] = 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    \n",
    "    return URM\n",
    "\n",
    "#\n",
    "# URM:\n",
    "# \n",
    "#              tracks\n",
    "#            _________\n",
    "#           \\         \\\n",
    "# playlists \\         \\\n",
    "#           \\_________\\\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n"
     ]
    }
   ],
   "source": [
    "URM_normalize = get_URM(tracks, playlists, playlist_tracks, track_playlists, norm=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n"
     ]
    }
   ],
   "source": [
    "URM_pow = get_URM(tracks, playlists, playlist_tracks, track_playlists, norm=\"pow\", pow_base=500, pow_exp=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, URM_normalize.shape[1]))#URM_pow.transpose()[0:row_group].dot(URM_pow) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "TTM_cosine = dot_with_top(URM_normalize.transpose(), URM_normalize, def_rows_i, top=50, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, URM_pow.shape[1]))#URM_pow.transpose()[0:row_group].dot(URM_pow) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "TTM_dot = dot_with_top(URM_pow.transpose(), URM_pow, def_rows_i, top=50, row_group=row_group, similarity=\"dot-old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-item similarity starting from a user-user similarity using only the URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n"
     ]
    }
   ],
   "source": [
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, URM_normalize.transpose().shape[1]))#URM_pow.transpose()[0:row_group].dot(URM_pow) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "UUM_cosine = dot_with_top(URM_normalize, URM_normalize.transpose(), def_rows_i, top=500, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n"
     ]
    }
   ],
   "source": [
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, UUM_cosine.transpose().shape[1]))#URM_pow.transpose()[0:row_group].dot(URM_pow) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "URM_UUM_cosine = dot_with_top(UUM_cosine, URM_normalize, def_rows_i, top=500, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, URM_UUM_cosine.shape[1]))#URM_pow.transpose()[0:row_group].dot(URM_pow) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "TTM_UUM_cosine = dot_with_top(URM_UUM_cosine.transpose(), URM_UUM_cosine, def_rows_i, top=50, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Calibration\n",
    "def calibrate_predictions(pred, theta=0.5):\n",
    "    max_r = np.amax(pred, axis=0)\n",
    "    mean_r = np.mean(pred, axis=0)\n",
    "\n",
    "    pred_coo = pred.tocoo()\n",
    "    pred_csr = pred.tocsr()\n",
    "    max_r_csr = max_r.tocsr()\n",
    "\n",
    "    counter = 0\n",
    "    for i,j,v in zip(pred_coo.row, pred_coo.col, pred_coo.data):\n",
    "        if v >= max_r_csr[0,j]:\n",
    "            pred_csr[i,j] = 1\n",
    "        elif v >= mean_r[0,j]:\n",
    "            pred_csr[i,j] = theta + (1 - theta)*((v - mean_r[0,j])/(max_r_csr[0,j] - mean_r[0,j]))\n",
    "        else:\n",
    "            pred_csr[i,j] = theta * v / mean_r[0,j]\n",
    "        counter += 1\n",
    "        if counter % 10000 == 0:\n",
    "            print(\"{0} out of {1}\".format(counter, len(pred.data)))\n",
    "    \n",
    "    return pred_csr\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Album\n",
    "\n",
    "<div style=\"white-space: pre-wrap;\">\n",
    "Steps:\n",
    "1 - Compute the playlists_x_albums (i.e. the UAM_album matrix, where U stands for User) sparse matrix. I do this before computing the tracks_x_albums (i.e. the IAM_album matrix, where I stands for Item) sparse matrix because here I compute also the \"album_to_val\" dictionary, which contains the IDF value of each album obtained considering the playlists as document (and not the tracks). However at the moment I don't use this because I compute the IAM_album matrix without any normalization, so you may skip it...\n",
    "2 - Compute the tracks_x_albums IAM_album sparse matrix.\n",
    "3 - Compute the SYM_ALBUM tracks_x_tracks matrix by doing IAM_album.dot(IAM_album.transpose()). It's not big, so I don't need to keep the K best values...\n",
    "4 - Compute the album_parameter, which means \"how much each playlist is affine to album similarity\". I do this by computing the entropy of the numpy array containing the occurrences of the albums in the playlist, and then doing 1/(entropy_of_array + 0.05).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     7,      8,      9, ..., 244079, 244080, 244081])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_albums = tracks.album.unique()\n",
    "unique_albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "album_tracks = {}\n",
    "for row in tracks.itertuples():\n",
    "    if row.album in album_tracks:\n",
    "        album_tracks[row.album].append(row.track_id)\n",
    "    else:\n",
    "        album_tracks[row.album] = [row.track_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_IAM_album(tracks, target_tracks, norm=\"no\", most_similar=5):\n",
    "    \"\"\"\n",
    "        Possible norms are \"no\", \"idf\", \"most-similar\".\n",
    "        Default \"no\".\n",
    "    \"\"\"\n",
    "    unique_albums = tracks.album.unique()\n",
    "    IAM_album = lil_matrix((len(tracks), max(unique_albums)+1))\n",
    "    \n",
    "    num_tracks = len(tracks)\n",
    "    i = 0\n",
    "    \n",
    "    if norm == \"most-similar\":\n",
    "        def get_album_sim(alb, n_best=5):\n",
    "            bests = []\n",
    "            a = ALB_ALB_SYM[alb].toarray()[0]\n",
    "            for i in range(n_best):\n",
    "                bests.append(a.argpartition(len(a)-1-i)[-1-i])\n",
    "            return bests\n",
    "\n",
    "        for row in tracks[tracks.track_id.isin(track_playlists.track_id)].itertuples():\n",
    "            bests = get_album_sim(row.album, n_best=5)\n",
    "            for it,alb in enumerate(bests):\n",
    "                IAM_album[row.track_id, alb] = 1 - it*0.1\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            i += 1\n",
    "            \n",
    "    else:\n",
    "        for row in tracks.itertuples():\n",
    "            nq = 1\n",
    "            if norm == \"idf\":\n",
    "                nq = len(album_tracks[row.album])\n",
    "                if row.album in album_to_val:\n",
    "                    IAM_album[row.track_id,row.album] = math.log(500/(nq + 0.5))\n",
    "                else:\n",
    "                    IAM_album[row.track_id,row.album] = 0 # Give zero if the album is not in any playlist!\n",
    "            else:\n",
    "                IAM_album[row.track_id,row.album] = 1\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            i += 1\n",
    "    \n",
    "    return IAM_album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n",
      "44900\n",
      "45000\n",
      "45100\n",
      "45200\n",
      "45300\n",
      "45400\n",
      "45500\n",
      "45600\n",
      "45700\n",
      "45800\n",
      "45900\n",
      "46000\n",
      "46100\n",
      "46200\n",
      "46300\n",
      "46400\n",
      "46500\n",
      "46600\n",
      "46700\n",
      "46800\n",
      "46900\n",
      "47000\n",
      "47100\n",
      "47200\n",
      "47300\n",
      "47400\n",
      "47500\n",
      "47600\n",
      "47700\n",
      "47800\n",
      "47900\n",
      "48000\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n",
      "48800\n",
      "48900\n",
      "49000\n",
      "49100\n",
      "49200\n",
      "49300\n",
      "49400\n",
      "49500\n",
      "49600\n",
      "49700\n",
      "49800\n",
      "49900\n",
      "50000\n",
      "50100\n",
      "50200\n",
      "50300\n",
      "50400\n",
      "50500\n",
      "50600\n",
      "50700\n",
      "50800\n",
      "50900\n",
      "51000\n",
      "51100\n",
      "51200\n",
      "51300\n",
      "51400\n",
      "51500\n",
      "51600\n",
      "51700\n",
      "51800\n",
      "51900\n",
      "52000\n",
      "52100\n",
      "52200\n",
      "52300\n",
      "52400\n",
      "52500\n",
      "52600\n",
      "52700\n",
      "52800\n",
      "52900\n",
      "53000\n",
      "53100\n",
      "53200\n",
      "53300\n",
      "53400\n",
      "53500\n",
      "53600\n",
      "53700\n",
      "53800\n",
      "53900\n",
      "54000\n",
      "54100\n",
      "54200\n",
      "54300\n",
      "54400\n",
      "54500\n",
      "54600\n",
      "54700\n",
      "54800\n",
      "54900\n",
      "55000\n",
      "55100\n",
      "55200\n",
      "55300\n",
      "55400\n",
      "55500\n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n",
      "69500\n",
      "69600\n",
      "69700\n",
      "69800\n",
      "69900\n",
      "70000\n",
      "70100\n",
      "70200\n",
      "70300\n",
      "70400\n",
      "70500\n",
      "70600\n",
      "70700\n",
      "70800\n",
      "70900\n",
      "71000\n",
      "71100\n",
      "71200\n",
      "71300\n",
      "71400\n",
      "71500\n",
      "71600\n",
      "71700\n",
      "71800\n",
      "71900\n",
      "72000\n",
      "72100\n",
      "72200\n",
      "72300\n",
      "72400\n",
      "72500\n",
      "72600\n",
      "72700\n",
      "72800\n",
      "72900\n",
      "73000\n",
      "73100\n",
      "73200\n",
      "73300\n",
      "73400\n",
      "73500\n",
      "73600\n",
      "73700\n",
      "73800\n",
      "73900\n",
      "74000\n",
      "74100\n",
      "74200\n",
      "74300\n",
      "74400\n",
      "74500\n",
      "74600\n",
      "74700\n",
      "74800\n",
      "74900\n",
      "75000\n",
      "75100\n",
      "75200\n",
      "75300\n",
      "75400\n",
      "75500\n",
      "75600\n",
      "75700\n",
      "75800\n",
      "75900\n",
      "76000\n",
      "76100\n",
      "76200\n",
      "76300\n",
      "76400\n",
      "76500\n",
      "76600\n",
      "76700\n",
      "76800\n",
      "76900\n",
      "77000\n",
      "77100\n",
      "77200\n",
      "77300\n",
      "77400\n",
      "77500\n",
      "77600\n",
      "77700\n",
      "77800\n",
      "77900\n",
      "78000\n",
      "78100\n",
      "78200\n",
      "78300\n",
      "78400\n",
      "78500\n",
      "78600\n",
      "78700\n",
      "78800\n",
      "78900\n",
      "79000\n",
      "79100\n",
      "79200\n",
      "79300\n",
      "79400\n",
      "79500\n",
      "79600\n",
      "79700\n",
      "79800\n",
      "79900\n",
      "80000\n",
      "80100\n",
      "80200\n",
      "80300\n",
      "80400\n",
      "80500\n",
      "80600\n",
      "80700\n",
      "80800\n",
      "80900\n",
      "81000\n",
      "81100\n",
      "81200\n",
      "81300\n",
      "81400\n",
      "81500\n",
      "81600\n",
      "81700\n",
      "81800\n",
      "81900\n",
      "82000\n",
      "82100\n",
      "82200\n",
      "82300\n",
      "82400\n",
      "82500\n",
      "82600\n",
      "82700\n",
      "82800\n",
      "82900\n",
      "83000\n",
      "83100\n",
      "83200\n",
      "83300\n",
      "83400\n",
      "83500\n",
      "83600\n",
      "83700\n",
      "83800\n",
      "83900\n",
      "84000\n",
      "84100\n",
      "84200\n",
      "84300\n",
      "84400\n",
      "84500\n",
      "84600\n",
      "84700\n",
      "84800\n",
      "84900\n",
      "85000\n",
      "85100\n",
      "85200\n",
      "85300\n",
      "85400\n",
      "85500\n",
      "85600\n",
      "85700\n",
      "85800\n",
      "85900\n",
      "86000\n",
      "86100\n",
      "86200\n",
      "86300\n",
      "86400\n",
      "86500\n",
      "86600\n",
      "86700\n",
      "86800\n",
      "86900\n",
      "87000\n",
      "87100\n",
      "87200\n",
      "87300\n",
      "87400\n",
      "87500\n",
      "87600\n",
      "87700\n",
      "87800\n",
      "87900\n",
      "88000\n",
      "88100\n",
      "88200\n",
      "88300\n",
      "88400\n",
      "88500\n",
      "88600\n",
      "88700\n",
      "88800\n",
      "88900\n",
      "89000\n",
      "89100\n",
      "89200\n",
      "89300\n",
      "89400\n",
      "89500\n",
      "89600\n",
      "89700\n",
      "89800\n",
      "89900\n",
      "90000\n",
      "90100\n",
      "90200\n",
      "90300\n",
      "90400\n",
      "90500\n",
      "90600\n",
      "90700\n",
      "90800\n",
      "90900\n",
      "91000\n",
      "91100\n",
      "91200\n",
      "91300\n",
      "91400\n",
      "91500\n",
      "91600\n",
      "91700\n",
      "91800\n",
      "91900\n",
      "92000\n",
      "92100\n",
      "92200\n",
      "92300\n",
      "92400\n",
      "92500\n",
      "92600\n",
      "92700\n",
      "92800\n",
      "92900\n",
      "93000\n",
      "93100\n",
      "93200\n",
      "93300\n",
      "93400\n",
      "93500\n",
      "93600\n",
      "93700\n",
      "93800\n",
      "93900\n",
      "94000\n",
      "94100\n",
      "94200\n",
      "94300\n",
      "94400\n",
      "94500\n",
      "94600\n",
      "94700\n",
      "94800\n",
      "94900\n",
      "95000\n",
      "95100\n",
      "95200\n",
      "95300\n",
      "95400\n",
      "95500\n",
      "95600\n",
      "95700\n",
      "95800\n",
      "95900\n",
      "96000\n",
      "96100\n",
      "96200\n",
      "96300\n",
      "96400\n",
      "96500\n",
      "96600\n",
      "96700\n",
      "96800\n",
      "96900\n",
      "97000\n",
      "97100\n",
      "97200\n",
      "97300\n",
      "97400\n",
      "97500\n",
      "97600\n",
      "97700\n",
      "97800\n",
      "97900\n",
      "98000\n",
      "98100\n",
      "98200\n",
      "98300\n",
      "98400\n",
      "98500\n",
      "98600\n",
      "98700\n",
      "98800\n",
      "98900\n",
      "99000\n",
      "99100\n",
      "99200\n",
      "99300\n",
      "99400\n",
      "99500\n",
      "99600\n",
      "99700\n",
      "99800\n",
      "99900\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "IAM_album = get_IAM_album(tracks, target_tracks, norm=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ALBUM = IAM_album.dot(IAM_album.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist\n",
    "Same steps as for Album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_artists = tracks.artist_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Item Artist Matrix\n",
    "def get_IAM(tracks, target_tracks, norm=\"no\", n_best=5):\n",
    "    \"\"\"\n",
    "        Possible norms are \"no\", \"idf\", \"most-similar\". Default to \"no\".\n",
    "    \"\"\"\n",
    "    unique_artists = tracks.artist_id.unique()\n",
    "    IAM = lil_matrix((len(tracks), max(unique_artists)+1))\n",
    "    \n",
    "    num_tracks = len(tracks)\n",
    "    i = 0\n",
    "    \n",
    "    if norm == \"most-similar\":\n",
    "        def get_artist_sim(art, n_best=5):\n",
    "            bests = []\n",
    "            a = ART_ART_SYM[art].toarray()[0]\n",
    "            for i in range(n_best):\n",
    "                bests.append(a.argpartition(len(a)-1-i)[-1-i])\n",
    "            return bests\n",
    "\n",
    "        for row in tracks[tracks.track_id.isin(track_playlists.track_id)].itertuples():\n",
    "            bests = get_artist_sim(row.artist_id, n_best=5)\n",
    "            for it,art in enumerate(bests):\n",
    "                IAM[row.track_id, art] = 1 - it*0.1\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            i += 1\n",
    "    else:\n",
    "        for row in tracks.itertuples():\n",
    "            if norm == \"idf\":\n",
    "                if row.artist_id in artist_to_val:\n",
    "                    IAM[row.track_id,row.artist_id] = artist_to_val[row.artist_id]\n",
    "                else:\n",
    "                    IAM[row.track_id,row.artist_id] = 0 # Give zero if the album is not in any playlist!\n",
    "            else:\n",
    "                IAM[row.track_id,row.artist_id] = 1\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "            i += 1\n",
    "    \n",
    "    return IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "IAM = get_IAM(tracks, target_tracks, norm=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "SYM_ARTIST = IAM.dot(IAM.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Item Tag Matrix ITM\n",
    "def get_ITM(tracks, tag_tracks, norm=\"no\", best_tag=False):\n",
    "    \"\"\"\n",
    "        Possible norm are \"no\", \"sqrt\", okapi\". Default to \"no\".\n",
    "    \"\"\"\n",
    "    if best_tag:\n",
    "        unique_tags = list(best_tag_tracks.keys())\n",
    "    else:\n",
    "        unique_tags = list(tag_tracks.keys())\n",
    "    ITM = lil_matrix((len(tracks), max(unique_tags)+1))\n",
    "    \n",
    "    num_tracks = len(tracks)\n",
    "    i = 0\n",
    "    \n",
    "    if best_tag:\n",
    "        tag_dict = best_tag_tracks\n",
    "    else:\n",
    "        tag_dict = tag_tracks\n",
    "        \n",
    "    for tag,track_ids in tag_dict.items():\n",
    "        nq = len(track_ids)\n",
    "        for track_id in track_ids:\n",
    "            if norm == \"okapi\":\n",
    "                ITM[track_id,tag] = math.log((num_tracks - nq + 0.5)/(nq + 0.5))\n",
    "            elif norm == \"sqrt\":\n",
    "                ITM[track_id,tag] = math.sqrt((num_tracks - nq + 0.5)/(nq + 0.5))\n",
    "            else:\n",
    "                ITM[track_id,tag] = 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    \n",
    "    return ITM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n"
     ]
    }
   ],
   "source": [
    "ITM = get_ITM(tracks, tag_tracks, norm=\"no\", best_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, ITM.shape[0])) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "SYM_TAG = dot_with_top(ITM, ITM.transpose(), def_rows_i, top=25, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other similarities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "UAM_album, UAM_album_no_norm, album_to_val = get_UAM_album(tracks, playlist_tracks, target_playlists, norm=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, UAM_album.shape[0]))#IAM_album[0:row_group].dot(UAM_album.transpose()) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "TR_PL_ALBUM = dot_with_top(IAM_album, UAM_album.transpose(), def_rows_i, top=200, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, TR_PL_ALBUM.shape[0]))#TR_PL_ALBUM[0:row_group].dot(TR_PL_ALBUM.transpose()) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "SYM_ALBUM_COMPLEX = dot_with_top(TR_PL_ALBUM, TR_PL_ALBUM.transpose(), def_rows_i, top=50, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Artist Matrix UAM\n",
    "def get_UAM(tracks, playlist_tracks, target_playlists, norm=\"no\", OKAPI_K=1.7, OKAPI_B=0.75):\n",
    "    \"\"\"\n",
    "        Possible norms are \"no\", \"idf\", okapi\". Default to \"no\".\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_artists = tracks.artist_id.unique()\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    UAM = lil_matrix((max(playlists.playlist_id)+1, max(unique_artists)+1))\n",
    "    UAM_no_norm = lil_matrix((max(playlists.playlist_id)+1, max(unique_artists)+1))\n",
    "    artist_to_playlists = {}\n",
    "    \n",
    "    for row in playlist_tracks.itertuples():\n",
    "        pl_id = row.playlist_id\n",
    "        for tr_id in row.track_ids:\n",
    "            art = tracks.loc[tr_id].artist_id\n",
    "            UAM[pl_id,art] += 1\n",
    "            UAM_no_norm[pl_id,art] += 1\n",
    "            if art not in artist_to_playlists:\n",
    "                artist_to_playlists[art] = [pl_id]\n",
    "            else:\n",
    "                artist_to_playlists[art].append(pl_id)\n",
    "                \n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    artist_to_val = {}\n",
    "    if norm == \"okapi\" or norm == \"idf\":\n",
    "        avg_document_length = functools.reduce(lambda acc,tr_ids: acc + len(tr_ids), playlist_tracks.track_ids, 0) / len(playlist_tracks)\n",
    "        N = len(playlist_tracks)\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for row in playlist_tracks.itertuples():\n",
    "            pl_id = row.playlist_id\n",
    "            artists = UAM.rows[pl_id]\n",
    "            data = UAM.data[pl_id]\n",
    "            for artist in artists:\n",
    "                fq = UAM[pl_id,artist]\n",
    "                nq = len(artist_to_playlists[artist])\n",
    "                idf = math.log((N - nq + 0.5)/(nq + 0.5))\n",
    "                \n",
    "                if artist not in artist_to_val:\n",
    "                    artist_to_val[artist] = idf\n",
    "                \n",
    "                if norm == \"idf\":\n",
    "                    UAM[pl_id,artist] = idf\n",
    "                else:\n",
    "                    UAM[pl_id,artist] = idf*(fq*(OKAPI_K+1))/(fq + OKAPI_K*(1 - OKAPI_B + OKAPI_B * sum(data) / avg_document_length))\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(i)\n",
    "    \n",
    "    return UAM, UAM_no_norm, artist_to_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "UAM, UAM_no_norm, artist_to_val = get_UAM(tracks, playlist_tracks, target_playlists, norm=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, UAM.shape[0]))#IAM[0:row_group].dot(UAM.transpose()) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "TR_PL_ARTIST = dot_with_top(IAM, UAM.transpose(), def_rows_i, top=200, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Step 2: produce item-item matrix with cosine similarity\n",
    "row_group = 1000\n",
    "def_rows_i = csr_matrix((row_group, TR_PL_ARTIST.shape[0]))#TR_PL_ARTIST[0:row_group].dot(TR_PL_ARTIST.transpose()) # this is needed to fill some rows that would be all zeros otherwise...\n",
    "SYM_ARTIST_COMPLEX = dot_with_top(TR_PL_ARTIST, TR_PL_ARTIST.transpose(), def_rows_i, top=50, row_group=row_group, similarity=\"cosine-old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_prediction_matrix_to_dataframe(pred_matrix, target_playlists, keep_best=5,\n",
    "                                       num_to_tracks={}, map_tracks=False):\n",
    "    pred_matrix_csr = pred_matrix.tocsr()\n",
    "\n",
    "    predictions = pd.DataFrame(target_playlists)\n",
    "    predictions.index = target_playlists['playlist_id']\n",
    "    predictions['track_ids'] = [np.array([]) for i in range(len(predictions))]\n",
    "\n",
    "    for target_row,pl_id in enumerate(target_playlists.playlist_id):\n",
    "        row_start = pred_matrix_csr.indptr[target_row]\n",
    "        row_end = pred_matrix_csr.indptr[target_row+1]\n",
    "        row_columns = pred_matrix_csr.indices[row_start:row_end]\n",
    "        row_data = pred_matrix_csr.data[row_start:row_end]\n",
    "\n",
    "        best_indexes = row_data.argsort()[::-1][:keep_best]\n",
    "        \n",
    "        pred = row_columns[best_indexes]\n",
    "        \n",
    "        if map_tracks:\n",
    "            pred = np.array([num_to_tracks[t] for t in pred])\n",
    "\n",
    "        predictions.loc[pl_id] = predictions.loc[pl_id].set_value('track_ids', pred)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimilarityPredictor:\n",
    "    def __init__(self, name, urm, similarity):\n",
    "        self.name = name\n",
    "        self.urm = urm\n",
    "        self.similarity = similarity\n",
    "        \n",
    "    def predict(self, original_urm, target_playlists, target_tracks, row_group=1000, keep_best=5, normalize_columns=True,\n",
    "                compute_MAP=False, test_good=\"nope\"):\n",
    "        print(self.name, end=' ')\n",
    "        \n",
    "        res_urm = csr_matrix((0, self.urm.shape[1]))\n",
    "        ttracks = list(set(target_tracks['track_id'].values))\n",
    "        \n",
    "        row_start = 0\n",
    "        while row_start < len(target_playlists):\n",
    "            # We'll do dot products for all playlists in \"target_playlists\" from \"row_start\" to \"row_end\"\n",
    "            row_end = row_start + row_group if row_start + row_group <= len(target_playlists) else len(target_playlists)\n",
    "\n",
    "            # \"pl_group\" is the set of the playlists that we want to make prediction for\n",
    "            pl_group = target_playlists[row_start:row_end]\n",
    "            \n",
    "            rows_URM = []\n",
    "            for pl_id in pl_group.playlist_id:\n",
    "                rows_URM += [self.urm[pl_id,:]]\n",
    "            composed_URM = scipy.sparse.vstack(rows_URM, 'csr')\n",
    "        \n",
    "            simil = np.array(np.divide(self.similarity.dot(composed_URM.transpose()).transpose().todense(), self.similarity.sum(axis=1).transpose() + 1))\n",
    "            \n",
    "            for i,pl_id in enumerate(pl_group.playlist_id):\n",
    "                row = simil[i]\n",
    "                pl_tracks = list(set(playlist_tracks.loc[pl_id]['track_ids']))\n",
    "                best_indexes = row.argsort()[::-1]\n",
    "                best_indexes = best_indexes[np.in1d(best_indexes, ttracks)] # keep only tracks that are in target_tracks\n",
    "                best_indexes = best_indexes[~np.in1d(best_indexes, pl_tracks)] # remove tracks that are already in the playlist\n",
    "                best_indexes = best_indexes[:keep_best] # keep only the best\n",
    "                new_row = np.zeros(len(row))\n",
    "                new_row[best_indexes] = row[best_indexes]\n",
    "                simil[i] = new_row\n",
    "            \n",
    "            res_urm = scipy.sparse.vstack([res_urm, simil], 'csr')\n",
    "            row_start = row_end\n",
    "            print(\".\", end='')\n",
    "        \n",
    "        print(\" \", end='')\n",
    "        if normalize_columns:\n",
    "            res_urm = normalize(res_urm, norm='l2', axis=0)\n",
    "            \n",
    "        if compute_MAP:\n",
    "            predictions = from_prediction_matrix_to_dataframe(res_urm, target_playlists, keep_best=5, num_to_tracks=num_to_tracks, map_tracks=True)\n",
    "            print(util.evaluate(test_good, predictions, should_transform_test=False))\n",
    "            \n",
    "        return res_urm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "class EnsemblePredictor:\n",
    "    def __init__(self, name, predictors):\n",
    "        self.name = name\n",
    "        self.predictors = predictors\n",
    "        \n",
    "    def predict(self, original_urm, target_playlists, target_tracks, row_group=1000, keep_best=5, normalize_columns=True,\n",
    "                compute_MAP=False, test_good=\"nope\"):\n",
    "        \n",
    "        predictions = []\n",
    "        for predictor in self.predictors:\n",
    "            pred = predictor.predict(URM_normalize, target_playlists, target_tracks, keep_best=keep_best, normalize_columns=normalize_columns, compute_MAP=compute_MAP, test_good=test_good)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        res_urm = functools.reduce(lambda p1,p2: p1.tolil() + p2.tolil(), predictions)\n",
    "        \n",
    "        if normalize_columns:\n",
    "            res_urm = normalize(res_urm, norm='l2', axis=0)\n",
    "            \n",
    "        print(self.name, end=' ')\n",
    "        \n",
    "        res_urm = res_urm.tolil()\n",
    "            \n",
    "        for i,pl_id in enumerate(target_playlists.playlist_id):\n",
    "            row = res_urm[i].toarray()[0]\n",
    "            best_indexes = row.argsort()[::-1]\n",
    "            best_indexes = best_indexes[:keep_best] # keep only the best\n",
    "            new_row = np.zeros(len(row))\n",
    "            new_row[best_indexes] = row[best_indexes]\n",
    "            res_urm[i] = new_row\n",
    "            if i % 1000 == 0:\n",
    "                print(\".\", end='')\n",
    "        \n",
    "        print(\" \", end='')\n",
    "        \n",
    "        if compute_MAP:\n",
    "            predictions = from_prediction_matrix_to_dataframe(res_urm, target_playlists, keep_best=5, num_to_tracks=num_to_tracks, map_tracks=True)\n",
    "            print(util.evaluate(test_good, predictions, should_transform_test=False))\n",
    "        \n",
    "        return res_urm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EnsembleSimilarityPredictor:\n",
    "    def __init__(self, name, predictors):\n",
    "        \"\"\" All predictors should be SimilarityPredictor \"\"\"\n",
    "        self.name = name\n",
    "        self.predictors = predictors\n",
    "        \n",
    "    def predict(self, original_urm, target_playlists, target_tracks, row_group=1000, keep_best=5, normalize_columns=True,\n",
    "                compute_MAP=False, test_good=\"nope\"):\n",
    "        \"\"\" TODO \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recsys import utility as utils\n",
    "\n",
    "def make_predictions(predictor, original_urm, target_playlists, target_tracks, \n",
    "                    compute_MAP=False, test=None):\n",
    "    \n",
    "    if compute_MAP:\n",
    "        test_good = get_playlist_track_list2(test)\n",
    "        test_good.index = test_good.playlist_id.apply(lambda pl_id: playlist_to_num[pl_id])\n",
    "    else:\n",
    "        test_good = \"nope\"\n",
    "        \n",
    "    pred = predictor.predict(original_urm, target_playlists, target_tracks, row_group=1000, keep_best=5, normalize_columns=False, compute_MAP=True, test_good=test_good)\n",
    "    \n",
    "    predictions = from_prediction_matrix_to_dataframe(pred, target_playlists, keep_best=5, num_to_tracks=num_to_tracks, map_tracks=True)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_dot_copy = TTM_dot.copy()\n",
    "TTM_cosine_copy = TTM_cosine.copy()\n",
    "TTM_UUM_cosine_copy = TTM_UUM_cosine.copy()\n",
    "SYM_ALBUM_copy = SYM_ALBUM.copy()\n",
    "SYM_ARTIST_copy = SYM_ARTIST.copy()\n",
    "SYM_TAG_copy = SYM_TAG.copy()\n",
    "SYM_ALBUM_COMPLEX_copy = SYM_ALBUM_COMPLEX.copy()\n",
    "SYM_ARTIST_COMPLEX_copy = SYM_ARTIST_COMPLEX.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_dot = TTM_dot_copy.copy()\n",
    "TTM_cosine = TTM_cosine_copy.copy()\n",
    "TTM_UUM_cosine = TTM_UUM_cosine_copy.copy()\n",
    "SYM_ALBUM = SYM_ALBUM_copy.copy()\n",
    "SYM_ARTIST = SYM_ARTIST_copy.copy()\n",
    "SYM_TAG = SYM_TAG_copy.copy()\n",
    "SYM_ALBUM_COMPLEX = SYM_ALBUM_COMPLEX_copy.copy()\n",
    "SYM_ARTIST_COMPLEX = SYM_ARTIST_COMPLEX_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "TTM_dot = normalize(TTM_dot, norm='l2', axis=0)\n",
    "TTM_cosine = normalize(TTM_cosine, norm='l2', axis=0)\n",
    "TTM_UUM_cosine = normalize(TTM_UUM_cosine, norm='l2', axis=0)\n",
    "SYM_ALBUM = normalize(SYM_ALBUM, norm='l1', axis=0)\n",
    "SYM_ARTIST = normalize(SYM_ARTIST, norm='l2', axis=0)\n",
    "SYM_TAG = normalize(SYM_TAG, norm='l2', axis=0)\n",
    "SYM_ALBUM_COMPLEX = normalize(SYM_ALBUM_COMPLEX, norm='l2', axis=0)\n",
    "SYM_ARTIST_COMPLEX = normalize(SYM_ARTIST_COMPLEX, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ii_1_predictor = SimilarityPredictor(\"ii_1_predictor\", URM_pow, TTM_dot)\n",
    "ii_2_predictor = SimilarityPredictor(\"ii_2_predictor\", URM_pow, TTM_cosine)\n",
    "ii_3_predictor = SimilarityPredictor(\"ii_3_predictor\", URM_pow, TTM_UUM_cosine)\n",
    "#tag_predictor = SimilarityPredictor(\"tag_predictor\", URM_pow, SYM_TAG)\n",
    "#ens_predictor_1 = EnsemblePredictor(\"ii+tag\", [ii_1_predictor, ii_2_predictor, ii_3_predictor, tag_predictor])\n",
    "\n",
    "album_predictor = SimilarityPredictor(\"album_predictor\", URM_pow, SYM_ALBUM)\n",
    "#album_cplx_predictor = SimilarityPredictor(\"album_cplx_predictor\", URM_pow, SYM_ALBUM_COMPLEX)\n",
    "#ens_predictor_2 = EnsemblePredictor(\"full_albums\", [album_predictor, album_cplx_predictor])\n",
    "\n",
    "artist_predictor = SimilarityPredictor(\"artist_predictor\", URM_pow, SYM_ARTIST)\n",
    "#artist_cplx_predictor = SimilarityPredictor(\"artist_cplx_predictor\", URM_pow, SYM_ARTIST_COMPLEX)\n",
    "#ens_predictor_3 = EnsemblePredictor(\"full_artists\", [artist_predictor, artist_cplx_predictor])\n",
    "\n",
    "final_predictor = EnsemblePredictor(\"final\", [ii_1_predictor, ii_2_predictor, ii_3_predictor, album_predictor, artist_predictor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii_1_predictor .."
     ]
    }
   ],
   "source": [
    "make_predictions(final_predictor, URM_normalize, target_playlists, target_tracks, compute_MAP=True, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare matrices for schwiftyness!\n",
    "Yoooo we're gonna get schwiftyyyyy: print all the info necessaries for get_schwifty.cpp to work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_similarity(matrix_to_print, directory, filename):\n",
    "    matrix_to_print = matrix_to_print.tocoo()\n",
    "\n",
    "    file = open(directory + \"/\" + filename + \".txt\",\"w\") \n",
    "\n",
    "    rows = matrix_to_print.row;\n",
    "    cols = matrix_to_print.col;\n",
    "    data = matrix_to_print.data;\n",
    "\n",
    "    file.write(\"{0} {1}\\n\".format(matrix_to_print.shape[0], matrix_to_print.shape[1]))\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(rows[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0,len(cols)):\n",
    "        file.write(\"{0} \".format(cols[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "        file.write(\"{0} \".format(data[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_URM(urm, directory, filename):\n",
    "    file = open(directory + \"/\" + filename + \".txt\",\"w\")\n",
    "    \n",
    "    urm_coo = urm.tocoo()\n",
    "\n",
    "    rows = urm_coo.row;\n",
    "    cols = urm_coo.col;\n",
    "    data = urm_coo.data;\n",
    "\n",
    "    file.write(\"{0} {1}\\n\".format(urm_coo.shape[0], urm_coo.shape[1]))\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(rows[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(cols[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(data[i]))\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    for pl_id in target_playlists.playlist_id:\n",
    "        file.write(\"{0} \".format(pl_id))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_test(urm, directory, filename):\n",
    "    file = open(directory + \"/\" + filename + \".txt\",\"w\")\n",
    "    \n",
    "    urm_coo = urm.tocoo()\n",
    "\n",
    "    rows = urm_coo.row;\n",
    "    cols = urm_coo.col;\n",
    "\n",
    "    file.write(\"{0} {1}\\n\".format(urm_coo.shape[0], urm_coo.shape[1]))\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(rows[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for i in range(0,len(rows)):\n",
    "        file.write(\"{0} \".format(cols[i]))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_target_playlists(target_playlists, directory, filename):\n",
    "    file = open(directory + \"/\" + filename + \".txt\",\"w\")\n",
    "    \n",
    "    file.write(\"{0}\\n\".format(len(target_playlists)))\n",
    "    for pl_id in target_playlists.playlist_id:\n",
    "        file.write(\"{0} \".format(pl_id))\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_target_tracks(target_tracks, directory, filename):\n",
    "    file = open(directory + \"/\" + filename + \".txt\",\"w\")\n",
    "    \n",
    "    file.write(\"{0}\\n\".format(len(target_tracks)))\n",
    "    for tr_id in target_tracks.track_id:\n",
    "        file.write(\"{0} \".format(tr_id))\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schwifty_directory = \"test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_URM(URM_pow, schwifty_directory, \"tracks_in_playlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"test['playlist_id_tmp'] = test['playlist_id']\n",
    "test['track_id_tmp'] = test['track_id']\n",
    "test['track_id'] = test['track_id'].apply(lambda x : track_to_num[x])\n",
    "test['playlist_id'] = test['playlist_id'].apply(lambda x : playlist_to_num[x])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Create a dataframe that maps a playlist to the set of its tracks\n",
    "playlist_tracks_test = pd.DataFrame(test['playlist_id'].drop_duplicates())\n",
    "playlist_tracks_test.index = test['playlist_id'].unique()\n",
    "playlist_tracks_test['track_ids'] = test.groupby('playlist_id').apply(lambda x : x['track_id'].values)\n",
    "playlist_tracks_test = playlist_tracks_test.sort_values('playlist_id')\n",
    "\n",
    "# Create a dataframe that maps a track to the set of the playlists it appears into\n",
    "track_playlists_test = pd.DataFrame(test['track_id'].drop_duplicates())\n",
    "track_playlists_test.index = test['track_id'].unique()\n",
    "track_playlists_test['playlist_ids'] = test.groupby('track_id').apply(lambda x : x['playlist_id'].values)\n",
    "track_playlists_test = track_playlists_test.sort_values('track_id')\n",
    "\n",
    "URM_test = get_URM(tracks, playlists, playlist_tracks_test, track_playlists_test, norm=\"no\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_test(URM_test, schwifty_directory, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_target_tracks(target_tracks, schwifty_directory, \"target_tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_target_playlists(target_playlists, schwifty_directory, \"target_playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_dot_copy = TTM_dot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_cosine_copy = TTM_cosine.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_UUM_cosine_copy = TTM_UUM_cosine.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ALBUM_copy = SYM_ALBUM.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ARTIST_copy = SYM_ARTIST.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_TAG_copy = SYM_TAG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_dot = TTM_dot_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_cosine = TTM_cosine_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_UUM_cosine = TTM_UUM_cosine_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ALBUM = SYM_ALBUM_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ARTIST = SYM_ARTIST_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_TAG = SYM_TAG_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_dot = normalize(TTM_dot, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_cosine = normalize(TTM_cosine, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTM_UUM_cosine = normalize(TTM_UUM_cosine, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ALBUM = normalize(SYM_ALBUM, norm='l1', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_ARTIST = normalize(SYM_ARTIST, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SYM_TAG = normalize(SYM_TAG, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_similarity(TTM_dot, schwifty_directory, \"similarity_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_similarity(TTM_cosine, schwifty_directory, \"similarity_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_similarity(TTM_UUM_cosine, schwifty_directory, \"similarity_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_similarity(SYM_ALBUM, schwifty_directory, \"similarity_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_similarity(SYM_ARTIST, schwifty_directory, \"similarity_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "def load_playlist_params(location, params_bitmask):\n",
    "    content = None\n",
    "    with open(os.path.join(location, 'playlist_params.txt'), 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    playlist_params = pd.DataFrame(playlists.playlist_id)\n",
    "    p = 0\n",
    "    for it,ch in enumerate(params_bitmask):\n",
    "        param_name = \"param_\" + str(it)\n",
    "        if ch == \"1\":\n",
    "            p_list = list(map(float, content[p].strip().split(' ')))\n",
    "            playlist_params[param_name] = Series(data=p_list, index=playlist_params.index)\n",
    "            p += 1\n",
    "        else:\n",
    "            playlist_params[param_name] = 0\n",
    "\n",
    "    return playlist_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call([\"./get_schwifty\", \"test1\", \"11111\", \"adadelta\", \"1000\", \"0.9\", \"0.3\", \"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>param_0</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>param_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.396839</td>\n",
       "      <td>0.444891</td>\n",
       "      <td>0.263535</td>\n",
       "      <td>1.407570</td>\n",
       "      <td>0.149888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.452189</td>\n",
       "      <td>0.499419</td>\n",
       "      <td>0.310674</td>\n",
       "      <td>1.616780</td>\n",
       "      <td>0.164639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.544483</td>\n",
       "      <td>0.578334</td>\n",
       "      <td>0.741585</td>\n",
       "      <td>0.371167</td>\n",
       "      <td>0.270944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.297131</td>\n",
       "      <td>0.323084</td>\n",
       "      <td>0.201349</td>\n",
       "      <td>1.195050</td>\n",
       "      <td>0.106432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.320824</td>\n",
       "      <td>0.300705</td>\n",
       "      <td>0.325097</td>\n",
       "      <td>0.776626</td>\n",
       "      <td>0.107159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.324306</td>\n",
       "      <td>0.188089</td>\n",
       "      <td>0.291868</td>\n",
       "      <td>0.137107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.712384</td>\n",
       "      <td>0.708510</td>\n",
       "      <td>0.658350</td>\n",
       "      <td>2.113440</td>\n",
       "      <td>0.124849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.558864</td>\n",
       "      <td>0.505409</td>\n",
       "      <td>0.472219</td>\n",
       "      <td>1.387100</td>\n",
       "      <td>1.369920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.306144</td>\n",
       "      <td>0.343912</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.793005</td>\n",
       "      <td>0.115241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.347881</td>\n",
       "      <td>0.386460</td>\n",
       "      <td>0.229181</td>\n",
       "      <td>1.732680</td>\n",
       "      <td>0.126787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.512478</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.423552</td>\n",
       "      <td>1.328480</td>\n",
       "      <td>0.133699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.601204</td>\n",
       "      <td>0.531808</td>\n",
       "      <td>0.392567</td>\n",
       "      <td>1.945980</td>\n",
       "      <td>1.683830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.312162</td>\n",
       "      <td>0.292370</td>\n",
       "      <td>0.151581</td>\n",
       "      <td>0.738758</td>\n",
       "      <td>0.049875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.235901</td>\n",
       "      <td>0.260091</td>\n",
       "      <td>0.179730</td>\n",
       "      <td>0.862427</td>\n",
       "      <td>0.047057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>0.621524</td>\n",
       "      <td>0.687784</td>\n",
       "      <td>0.465437</td>\n",
       "      <td>0.692218</td>\n",
       "      <td>0.399058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>0.369422</td>\n",
       "      <td>0.408823</td>\n",
       "      <td>0.144849</td>\n",
       "      <td>0.609990</td>\n",
       "      <td>0.234681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>0.472313</td>\n",
       "      <td>0.451134</td>\n",
       "      <td>0.389051</td>\n",
       "      <td>0.560982</td>\n",
       "      <td>0.155324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>0.285110</td>\n",
       "      <td>0.338388</td>\n",
       "      <td>0.238575</td>\n",
       "      <td>0.284174</td>\n",
       "      <td>0.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>0.459988</td>\n",
       "      <td>0.468766</td>\n",
       "      <td>0.348472</td>\n",
       "      <td>0.490756</td>\n",
       "      <td>0.395759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.260725</td>\n",
       "      <td>1.861330</td>\n",
       "      <td>0.575840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>0.591818</td>\n",
       "      <td>0.536574</td>\n",
       "      <td>0.500037</td>\n",
       "      <td>1.847400</td>\n",
       "      <td>0.302171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>156</td>\n",
       "      <td>0.532636</td>\n",
       "      <td>0.522542</td>\n",
       "      <td>0.405788</td>\n",
       "      <td>1.775940</td>\n",
       "      <td>0.362696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>0.317546</td>\n",
       "      <td>0.359154</td>\n",
       "      <td>0.179923</td>\n",
       "      <td>1.389300</td>\n",
       "      <td>0.463666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0.716717</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>0.745691</td>\n",
       "      <td>1.358360</td>\n",
       "      <td>0.330569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0.440115</td>\n",
       "      <td>0.513806</td>\n",
       "      <td>0.410942</td>\n",
       "      <td>0.265517</td>\n",
       "      <td>0.061216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>0.204822</td>\n",
       "      <td>0.221531</td>\n",
       "      <td>0.084095</td>\n",
       "      <td>0.414031</td>\n",
       "      <td>0.109626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>0.685078</td>\n",
       "      <td>0.632971</td>\n",
       "      <td>0.697299</td>\n",
       "      <td>0.946784</td>\n",
       "      <td>0.219220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.421044</td>\n",
       "      <td>0.414249</td>\n",
       "      <td>0.414276</td>\n",
       "      <td>0.479172</td>\n",
       "      <td>0.226395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>0.532542</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.420529</td>\n",
       "      <td>0.840416</td>\n",
       "      <td>0.095937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>0.351922</td>\n",
       "      <td>0.407250</td>\n",
       "      <td>0.278579</td>\n",
       "      <td>1.617160</td>\n",
       "      <td>0.134333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57338</th>\n",
       "      <td>57338</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.425264</td>\n",
       "      <td>0.288930</td>\n",
       "      <td>1.455010</td>\n",
       "      <td>0.086101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57340</th>\n",
       "      <td>57340</td>\n",
       "      <td>0.361831</td>\n",
       "      <td>0.305495</td>\n",
       "      <td>0.223177</td>\n",
       "      <td>0.413715</td>\n",
       "      <td>0.064435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57344</th>\n",
       "      <td>57344</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.355449</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>1.909380</td>\n",
       "      <td>0.151285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57351</th>\n",
       "      <td>57351</td>\n",
       "      <td>0.626930</td>\n",
       "      <td>0.641371</td>\n",
       "      <td>0.676779</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.214157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57367</th>\n",
       "      <td>57367</td>\n",
       "      <td>0.664550</td>\n",
       "      <td>0.637431</td>\n",
       "      <td>0.548124</td>\n",
       "      <td>0.617126</td>\n",
       "      <td>0.280744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57368</th>\n",
       "      <td>57368</td>\n",
       "      <td>0.348910</td>\n",
       "      <td>0.376088</td>\n",
       "      <td>0.184964</td>\n",
       "      <td>0.147768</td>\n",
       "      <td>0.066966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57369</th>\n",
       "      <td>57369</td>\n",
       "      <td>0.561565</td>\n",
       "      <td>0.527322</td>\n",
       "      <td>0.317204</td>\n",
       "      <td>1.149160</td>\n",
       "      <td>0.344945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57374</th>\n",
       "      <td>57374</td>\n",
       "      <td>0.435868</td>\n",
       "      <td>0.449091</td>\n",
       "      <td>0.169946</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>0.177150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57375</th>\n",
       "      <td>57375</td>\n",
       "      <td>0.686855</td>\n",
       "      <td>0.671193</td>\n",
       "      <td>0.672766</td>\n",
       "      <td>1.142760</td>\n",
       "      <td>0.285253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57389</th>\n",
       "      <td>57389</td>\n",
       "      <td>0.506242</td>\n",
       "      <td>0.500268</td>\n",
       "      <td>0.623842</td>\n",
       "      <td>0.463184</td>\n",
       "      <td>0.250970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57390</th>\n",
       "      <td>57390</td>\n",
       "      <td>0.849019</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.512990</td>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.337774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57396</th>\n",
       "      <td>57396</td>\n",
       "      <td>0.506509</td>\n",
       "      <td>0.441215</td>\n",
       "      <td>0.298122</td>\n",
       "      <td>0.269537</td>\n",
       "      <td>0.172082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57404</th>\n",
       "      <td>57404</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.409787</td>\n",
       "      <td>0.360354</td>\n",
       "      <td>0.827365</td>\n",
       "      <td>0.370401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57416</th>\n",
       "      <td>57416</td>\n",
       "      <td>0.822351</td>\n",
       "      <td>0.863537</td>\n",
       "      <td>0.460461</td>\n",
       "      <td>0.451388</td>\n",
       "      <td>0.181583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57429</th>\n",
       "      <td>57429</td>\n",
       "      <td>0.210543</td>\n",
       "      <td>0.248417</td>\n",
       "      <td>0.087592</td>\n",
       "      <td>0.120167</td>\n",
       "      <td>0.037224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>57474</td>\n",
       "      <td>0.239118</td>\n",
       "      <td>0.267309</td>\n",
       "      <td>0.332368</td>\n",
       "      <td>0.490108</td>\n",
       "      <td>0.055054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>57475</td>\n",
       "      <td>0.223599</td>\n",
       "      <td>0.226339</td>\n",
       "      <td>0.136626</td>\n",
       "      <td>0.666764</td>\n",
       "      <td>0.051642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57498</th>\n",
       "      <td>57498</td>\n",
       "      <td>0.494882</td>\n",
       "      <td>0.546524</td>\n",
       "      <td>0.452395</td>\n",
       "      <td>1.621780</td>\n",
       "      <td>0.334830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57500</th>\n",
       "      <td>57500</td>\n",
       "      <td>0.479881</td>\n",
       "      <td>0.499859</td>\n",
       "      <td>0.258769</td>\n",
       "      <td>1.370630</td>\n",
       "      <td>0.155216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57512</th>\n",
       "      <td>57512</td>\n",
       "      <td>0.195229</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.080453</td>\n",
       "      <td>0.479648</td>\n",
       "      <td>0.060673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57515</th>\n",
       "      <td>57515</td>\n",
       "      <td>0.226341</td>\n",
       "      <td>0.250163</td>\n",
       "      <td>0.108187</td>\n",
       "      <td>0.171073</td>\n",
       "      <td>0.064822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57516</th>\n",
       "      <td>57516</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>0.372955</td>\n",
       "      <td>0.135158</td>\n",
       "      <td>0.753263</td>\n",
       "      <td>0.162850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57531</th>\n",
       "      <td>57531</td>\n",
       "      <td>0.378719</td>\n",
       "      <td>0.417847</td>\n",
       "      <td>0.239524</td>\n",
       "      <td>1.373330</td>\n",
       "      <td>0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57535</th>\n",
       "      <td>57535</td>\n",
       "      <td>0.768908</td>\n",
       "      <td>0.764011</td>\n",
       "      <td>0.614786</td>\n",
       "      <td>1.959240</td>\n",
       "      <td>0.177585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57538</th>\n",
       "      <td>57538</td>\n",
       "      <td>0.964086</td>\n",
       "      <td>0.959105</td>\n",
       "      <td>0.670251</td>\n",
       "      <td>0.741241</td>\n",
       "      <td>0.581887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57540</th>\n",
       "      <td>57540</td>\n",
       "      <td>0.300421</td>\n",
       "      <td>0.350137</td>\n",
       "      <td>0.460970</td>\n",
       "      <td>1.782660</td>\n",
       "      <td>0.459672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57542</th>\n",
       "      <td>57542</td>\n",
       "      <td>0.671644</td>\n",
       "      <td>0.677545</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.659269</td>\n",
       "      <td>0.171480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57543</th>\n",
       "      <td>57543</td>\n",
       "      <td>0.677353</td>\n",
       "      <td>0.611319</td>\n",
       "      <td>0.346977</td>\n",
       "      <td>1.768620</td>\n",
       "      <td>0.254921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57545</th>\n",
       "      <td>57545</td>\n",
       "      <td>0.336184</td>\n",
       "      <td>0.398167</td>\n",
       "      <td>0.221640</td>\n",
       "      <td>0.738467</td>\n",
       "      <td>0.125385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57548</th>\n",
       "      <td>57548</td>\n",
       "      <td>0.491331</td>\n",
       "      <td>0.450325</td>\n",
       "      <td>0.462692</td>\n",
       "      <td>0.874834</td>\n",
       "      <td>0.125944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6658 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       playlist_id   param_0   param_1   param_2   param_3   param_4\n",
       "0                0  0.396839  0.444891  0.263535  1.407570  0.149888\n",
       "4                4  0.452189  0.499419  0.310674  1.616780  0.164639\n",
       "5                5  0.544483  0.578334  0.741585  0.371167  0.270944\n",
       "6                6  0.297131  0.323084  0.201349  1.195050  0.106432\n",
       "8                8  0.320824  0.300705  0.325097  0.776626  0.107159\n",
       "23              23  0.254940  0.324306  0.188089  0.291868  0.137107\n",
       "28              28  0.712384  0.708510  0.658350  2.113440  0.124849\n",
       "38              38  0.558864  0.505409  0.472219  1.387100  1.369920\n",
       "43              43  0.306144  0.343912  0.196970  0.793005  0.115241\n",
       "54              54  0.347881  0.386460  0.229181  1.732680  0.126787\n",
       "55              55  0.512478  0.508264  0.423552  1.328480  0.133699\n",
       "71              71  0.601204  0.531808  0.392567  1.945980  1.683830\n",
       "76              76  0.312162  0.292370  0.151581  0.738758  0.049875\n",
       "94              94  0.235901  0.260091  0.179730  0.862427  0.047057\n",
       "103            103  0.621524  0.687784  0.465437  0.692218  0.399058\n",
       "124            124  0.369422  0.408823  0.144849  0.609990  0.234681\n",
       "132            132  0.472313  0.451134  0.389051  0.560982  0.155324\n",
       "140            140  0.285110  0.338388  0.238575  0.284174  0.012566\n",
       "151            151  0.459988  0.468766  0.348472  0.490756  0.395759\n",
       "154            154  0.354839  0.469800  0.260725  1.861330  0.575840\n",
       "155            155  0.591818  0.536574  0.500037  1.847400  0.302171\n",
       "156            156  0.532636  0.522542  0.405788  1.775940  0.362696\n",
       "159            159  0.317546  0.359154  0.179923  1.389300  0.463666\n",
       "170            170  0.716717  0.719947  0.745691  1.358360  0.330569\n",
       "181            181  0.440115  0.513806  0.410942  0.265517  0.061216\n",
       "186            186  0.204822  0.221531  0.084095  0.414031  0.109626\n",
       "192            192  0.685078  0.632971  0.697299  0.946784  0.219220\n",
       "195            195  0.421044  0.414249  0.414276  0.479172  0.226395\n",
       "217            217  0.532542  0.574844  0.420529  0.840416  0.095937\n",
       "234            234  0.351922  0.407250  0.278579  1.617160  0.134333\n",
       "...            ...       ...       ...       ...       ...       ...\n",
       "57338        57338  0.399790  0.425264  0.288930  1.455010  0.086101\n",
       "57340        57340  0.361831  0.305495  0.223177  0.413715  0.064435\n",
       "57344        57344  0.380821  0.355449  0.392728  1.909380  0.151285\n",
       "57351        57351  0.626930  0.641371  0.676779  0.808906  0.214157\n",
       "57367        57367  0.664550  0.637431  0.548124  0.617126  0.280744\n",
       "57368        57368  0.348910  0.376088  0.184964  0.147768  0.066966\n",
       "57369        57369  0.561565  0.527322  0.317204  1.149160  0.344945\n",
       "57374        57374  0.435868  0.449091  0.169946  0.587452  0.177150\n",
       "57375        57375  0.686855  0.671193  0.672766  1.142760  0.285253\n",
       "57389        57389  0.506242  0.500268  0.623842  0.463184  0.250970\n",
       "57390        57390  0.849019  0.782805  0.512990  0.759072  0.337774\n",
       "57396        57396  0.506509  0.441215  0.298122  0.269537  0.172082\n",
       "57404        57404  0.373550  0.409787  0.360354  0.827365  0.370401\n",
       "57416        57416  0.822351  0.863537  0.460461  0.451388  0.181583\n",
       "57429        57429  0.210543  0.248417  0.087592  0.120167  0.037224\n",
       "57474        57474  0.239118  0.267309  0.332368  0.490108  0.055054\n",
       "57475        57475  0.223599  0.226339  0.136626  0.666764  0.051642\n",
       "57498        57498  0.494882  0.546524  0.452395  1.621780  0.334830\n",
       "57500        57500  0.479881  0.499859  0.258769  1.370630  0.155216\n",
       "57512        57512  0.195229  0.205200  0.080453  0.479648  0.060673\n",
       "57515        57515  0.226341  0.250163  0.108187  0.171073  0.064822\n",
       "57516        57516  0.348422  0.372955  0.135158  0.753263  0.162850\n",
       "57531        57531  0.378719  0.417847  0.239524  1.373330  0.027377\n",
       "57535        57535  0.768908  0.764011  0.614786  1.959240  0.177585\n",
       "57538        57538  0.964086  0.959105  0.670251  0.741241  0.581887\n",
       "57540        57540  0.300421  0.350137  0.460970  1.782660  0.459672\n",
       "57542        57542  0.671644  0.677545  0.637243  0.659269  0.171480\n",
       "57543        57543  0.677353  0.611319  0.346977  1.768620  0.254921\n",
       "57545        57545  0.336184  0.398167  0.221640  0.738467  0.125385\n",
       "57548        57548  0.491331  0.450325  0.462692  0.874834  0.125944\n",
       "\n",
       "[6658 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_params = load_playlist_params(\"test1\", \"11111\")\n",
    "playlist_params[playlist_params.playlist_id.isin(target_playlists.playlist_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_params = pd.DataFrame(playlists.playlist_id)\n",
    "playlist_params[\"param_0\"] = 1\n",
    "playlist_params[\"param_1\"] = 1\n",
    "playlist_params[\"param_2\"] = 1\n",
    "playlist_params[\"param_3\"] = 1\n",
    "playlist_params[\"param_4\"] = 1\n",
    "playlist_params[\"param_5\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6658\n",
      "1000\n",
      "0.0817233333333334\n",
      "2000\n",
      "0.08305499999999974\n",
      "3000\n",
      "0.08216444444444403\n",
      "4000\n",
      "0.08051249999999989\n",
      "5000\n",
      "0.08277933333333343\n",
      "6000\n",
      "0.08127000000000023\n",
      "6658\n",
      "0.08147892259937964\n"
     ]
    }
   ],
   "source": [
    "similarities = [TTM_dot, TTM_cosine, TTM_UUM_cosine, SYM_ALBUM, SYM_ARTIST]\n",
    "\n",
    "predictions = make_predictions(test=test, target_playlists=target_playlists, urm=URM_pow,\n",
    "                 similarities=similarities, playlist_params=playlist_params,\n",
    "                 compute_MAP=True, row_group=1000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.0819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(test=None, target_playlists=None, urm=None,\n",
    "                     similarities=[], playlist_params=None,\n",
    "                     compute_MAP=False, row_group=100, verbose=False):\n",
    "    \"\"\"\n",
    "        Produces a prediction dataframe for \"test\", where each row corresponds to a playlist in \"target_playlists\".\n",
    "        If compute_MAP is true, then it print the MAP every \"row_group\" playlists.\n",
    "        It's optimized for doing dot products for different playlist at once.\n",
    "            \"row_group\" is the number of playlists in each of these optimized dot products.\n",
    "            The higher is row_group, the faster are the predictions but more memory is used.\n",
    "            \n",
    "        All predictions are done in the following way:\n",
    "            bi\n",
    "            \n",
    "        Arguments:\n",
    "            - test: needed for computing MAP\n",
    "            - target_playlists: a dataframe containing the target playlists we want to predict for\n",
    "            - urm: the urm used for making predictions\n",
    "            - similarities: list with similarities used for making predictions\n",
    "            - playlist_params: dataframe containing parameters used for doing predictions. The name comvention\n",
    "                is the following: the parameter for SYM_0 is \"param_0\", etc...\n",
    "    \"\"\"\n",
    "    # Create predictions dataframe\n",
    "    predictions = pd.DataFrame(target_playlists)\n",
    "    predictions.index = target_playlists['playlist_id']\n",
    "    predictions['track_ids'] = [np.array([]) for i in range(len(predictions))]\n",
    "    predictions['track_ids_not_mapped'] = [np.array([]) for i in range(len(predictions))]\n",
    "    ttracks = set(target_tracks['track_id'].values)\n",
    "    if compute_MAP:\n",
    "        test_good = get_playlist_track_list2(test)\n",
    "        test_good.index = test_good.playlist_id.apply(lambda pl_id: playlist_to_num[pl_id])\n",
    "        print(len(test_good))\n",
    "    \n",
    "    # This is the sum of all the AP of the playlists.\n",
    "    # When we print the MAP, we divide \"sum_ap\" by the number of considered playlists.\n",
    "    sum_ap = 0\n",
    "    \n",
    "    # Let's start the predictions!\n",
    "    row_start = 0\n",
    "    while row_start < len(target_playlists):\n",
    "        # We'll do dot products for all playlists in \"target_playlists\" from \"row_start\" to \"row_end\"\n",
    "        row_end = row_start + row_group if row_start + row_group <= len(target_playlists) else len(target_playlists)\n",
    "        \n",
    "        # \"pl_group\" is the set of the playlists that we want to make prediction for\n",
    "        pl_group = target_playlists[row_start:row_end]\n",
    "        \n",
    "        # Now we need to build a matrix where, for each playlist in \"pl_group\", we take the correspondent URM row slice\n",
    "        rows_URM = []\n",
    "        for pl_id in pl_group.playlist_id:\n",
    "            rows_URM += [urm[pl_id,:]]\n",
    "        composed_URM = scipy.sparse.vstack(rows_URM, 'csr')\n",
    "        \n",
    "        # Compute predictions for current playlist group: here we do all the smart dot products...\n",
    "        simil_ar = []\n",
    "        for SYM in similarities:\n",
    "            simil_ar.append(np.array(np.divide(SYM.dot(composed_URM.transpose()).transpose().todense(), SYM.sum(axis=1).transpose() + 1)))\n",
    "            #simil_ar.append(np.array(SYM.dot(composed_URM.transpose()).transpose().todense()))\n",
    "            #simil_ar.append(np.array(cosine_similarity(SYM, composed_URM).transpose()))\n",
    "                            \n",
    "        # Now we should consider one playlist at a time, take its own personalized parameters and make the prediction\n",
    "        for i,pl_id in enumerate(pl_group.playlist_id):\n",
    "            # Tracks that we know are in the playlist (so we shouldn't recommend them)\n",
    "            pl_tracks = set(playlist_tracks.loc[pl_id]['track_ids'])\n",
    "            \n",
    "            # Retrieve parameters\n",
    "            params = []\n",
    "            for it,SYM in enumerate(similarities):\n",
    "                params.append(playlist_params.loc[pl_id][\"param_\" + str(it)])\n",
    "\n",
    "            simil = params[0] * simil_ar[0][i]\n",
    "            for p in range(1,len(simil_ar)):\n",
    "                simil += params[p] * simil_ar[p][i]\n",
    "            sorted_ind = simil.argsort()[::-1]\n",
    "\n",
    "            # Predict...\n",
    "            pred_not_mapped = []\n",
    "            pred = []\n",
    "            i = 0\n",
    "            while i < len(sorted_ind) and len(pred) < 5:\n",
    "                tr = sorted_ind[i]\n",
    "                if (tr in ttracks) and (tr not in pl_tracks) and (num_to_tracks[tr] not in pred):\n",
    "                    pred_not_mapped.append(tr)\n",
    "                    pred.append(num_to_tracks[tr])\n",
    "                i+=1\n",
    "            \n",
    "            predictions.loc[pl_id] = predictions.loc[pl_id].set_value('track_ids_not_mapped', np.array(pred_not_mapped))\n",
    "            predictions.loc[pl_id] = predictions.loc[pl_id].set_value('track_ids', np.array(pred))\n",
    "            \n",
    "            # Update MAP\n",
    "            if compute_MAP:\n",
    "                correct = 0\n",
    "                ap = 0\n",
    "                for it, t in enumerate(pred):\n",
    "                    tr_ids = test_good.loc[pl_id]['track_ids']\n",
    "                    if t in tr_ids:\n",
    "                        correct += 1\n",
    "                        ap += correct / (it+1)\n",
    "                ap /= len(pred)\n",
    "                sum_ap += ap\n",
    "        \n",
    "        # Update \"row_start\" to \"row_end\" and proceed to next pl_group\n",
    "        row_start = row_end\n",
    "        \n",
    "        print(row_start)\n",
    "        if compute_MAP:\n",
    "            print(sum_ap / row_start)\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_copy = predictions.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['playlist_id'] = predictions['playlist_id_tmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predictions.drop(\"playlist_id_tmp\", axis=1)\n",
    "predictions = predictions.drop(\"track_ids_not_mapped\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the dataframe friendly for output -> convert np.array in string\n",
    "predictions['track_ids'] = predictions['track_ids'].apply(lambda x : ' '.join(map(str, x)))\n",
    "predictions.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
