{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from recsys.preprocess import *\n",
    "from recsys.utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_things(location, has_test = True):\n",
    "    global train, test, playlists, tracks, target_tracks, target_playlists, tracks_in_playlist, tracks_target_only\n",
    "\n",
    "    train = pd.read_csv(os.path.join(location, 'train.csv'))\n",
    "    target_playlists = pd.read_csv(os.path.join(location, 'target_playlists.csv'))\n",
    "    target_tracks = pd.read_csv(os.path.join(location, 'target_tracks.csv'))\n",
    "\n",
    "    playlists = pd.read_csv('data/playlists_final.csv', delimiter='\\t')\n",
    "    tracks = pd.read_csv('data/tracks_final.csv', delimiter='\\t')\n",
    "\n",
    "    #tracks['tags'] = tracks['tags'].apply(lambda x: np.array(eval(x)))\n",
    "    tracks.index = tracks.track_id\n",
    "\n",
    "    tracks_in_playlist = get_playlist_track_list2(train)\n",
    "    tracks_target_only = tracks[tracks.track_id.isin(target_tracks.track_id)]\n",
    "    \n",
    "    if has_test:\n",
    "        test = pd.read_csv(os.path.join(location, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_similarity(location):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    content = None\n",
    "    with open(os.path.join(location, 'similarity_bpr.txt'), 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    row = list(map(int, content[1].strip().split(' ')))\n",
    "    col = list(map(int, content[2].strip().split(' ')))\n",
    "    data = list(map(float, content[3].strip().split(' ')))\n",
    "\n",
    "    coo = coo_matrix((data, (row, col)), shape=(100000, 100000))\n",
    "    csr = coo.tocsr()\n",
    "\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_num_to_id(df, row_num, column = 'track_id'):\n",
    "    \"\"\" df must have a 'track_id' column \"\"\"\n",
    "    return df.iloc[row_num][column]\n",
    "\n",
    "def from_id_to_num(df, tr_id, column='track_id'):\n",
    "    \"\"\" df must have a 'track_id' column \"\"\"\n",
    "    return np.where(df[column].values == tr_id)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_id_to_num_map(df, column):\n",
    "    a = pd.Series(np.arange(len(df)))\n",
    "    a.index = df[column]\n",
    "    return a\n",
    "\n",
    "def build_num_to_id_map(df, column):\n",
    "    a = pd.Series(df[column])\n",
    "    a.index = np.arange(len(df))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_URM():\n",
    "    tr_map = build_id_to_num_map(tracks, 'track_id')\n",
    "    pl_map = build_id_to_num_map(playlists, 'playlist_id')\n",
    "    \n",
    "    train_new = pd.DataFrame()\n",
    "    train_new['track_id'] = train['track_id'].apply(lambda x : tr_map[x])\n",
    "    train_new['playlist_id'] = train['playlist_id'].apply(lambda x : pl_map[x])\n",
    "    \n",
    "    rows = train_new['playlist_id'].values\n",
    "    cols = train_new['track_id'].values\n",
    "    values = np.ones(len(train_new))\n",
    "    \n",
    "    M = coo_matrix((values, (rows, cols)))\n",
    "    return M.tocsr()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set location of the folder with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = 'test5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_things(location, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 190 ms, total: 19 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "M = load_URM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n",
      "argh\n"
     ]
    }
   ],
   "source": [
    "M = M.tocsc()\n",
    "max_pl_length = M.sum(0).A.max()\n",
    "for i in range(M.shape[1]):\n",
    "    n_playlist = M.indptr[i+1] - M.indptr[i]\n",
    "    if n_playlist >= 1:\n",
    "        M.data[M.indptr[i]:M.indptr[i+1]] = np.repeat(math.sqrt((500) / (n_playlist)), n_playlist)\n",
    "    else:\n",
    "        print(\"argh\")\n",
    "        M.data[M.indptr[i]:M.indptr[i+1]] = np.repeat(math.sqrt((500) / (n_playlist+5)), n_playlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction #1: dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result so far: \n",
    "\n",
    "- 1.5 0.7 0 0 0.1 0 0.01   --> 0.0735\n",
    "- 1.5 0.7 0 0 0.1 0 0 --> 0.0710\n",
    "- 1 0.7 0.01 0 0.3 0 0 --> 0.0669\n",
    "- 1.4 0.7 0.01 0 0.3 0 0.5 --> 0.0659\n",
    "- 1.4 0.7 0.01 0 0.3 0.4 0.01 --> 0.0638\n",
    "- 1.5 0.7 0 0 0.1 0 0 --> 0.07108\n",
    "- 1.5 0.7 0 0 0.1 0 0.02 --> 0.07346\n",
    "- 1.5 0.7 0 0 0.1 0 0.1 --> 0.734\n",
    "- 1.7 0.7 0 0 0.1 0 0.5 --> 0.0585\n",
    "\n",
    "== dataset 2\n",
    "\n",
    "- 1.5 0.7 0.1 0 0.1 0 0.01 --> 0.07207\n",
    "\n",
    "(restoring tag idf)\n",
    "- 1.5 0.7 0.1 0 0.1 0 0.01 --> 0.0742\n",
    "- 1.5 0.7 0 0 0.3 0 0.01 --> 0.07166\n",
    "- 1.5 0.5 0.01 0.01 0.1 0 0.01 --> 0.07165\n",
    "\n",
    "== dataset 3\n",
    "- 1.5 0.7 0.1 0 0.1 0 0.01 --> 0.0722\n",
    "\n",
    "(using tag IDF log(100000/#tag_freq)\n",
    "\n",
    "== dataset 5\n",
    "- 1.5 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.07548  (URM changed)\n",
    "- 1 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.0739   (URM changed)\n",
    "- 1 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.0715\n",
    "\n",
    "== dataset 7\n",
    "- 1.5 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.0723\n",
    "- 1.5 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.07467 (URM changed)\n",
    "- 1.5 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.07585 (URM changed v.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = load_similarity(location)\n",
    "S2 = S.copy()\n",
    "S2 = S2.transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl2id_map = build_num_to_id_map(playlists, 'playlist_id')\n",
    "tr2id_map = build_num_to_id_map(tracks, 'track_id')\n",
    "pl2num_map = build_id_to_num_map(playlists, 'playlist_id')\n",
    "\n",
    "M = M.tocsr()\n",
    "predictions = {}\n",
    "for pl_id in target_playlists['playlist_id'].values:\n",
    "    pl_num = pl2num_map[pl_id]\n",
    "    r = M[pl_num,:].dot(S2)\n",
    "    idx = r.data.argsort()\n",
    "    ranking = np.flip(r.indices[idx], 0)\n",
    "    \n",
    "    count = 0\n",
    "    i = 0\n",
    "    pred = []\n",
    "    while count < 5 and i < len(ranking):\n",
    "        tr_id = tr2id_map[ranking[i]]\n",
    "        if tr_id not in tracks_in_playlist.loc[pl_id]['track_ids'] and tr_id in target_tracks['track_id'].values:\n",
    "            pred.append(tr_id)\n",
    "            count +=1\n",
    "        i+=1\n",
    "    i=0\n",
    "    if (len(pred) < 5):\n",
    "        print(\"aaaargh len < 5\")\n",
    "        print(\"{0}\".format(pl_num))\n",
    "    while len(pred) < 5 and i < len(ranking):\n",
    "        pred.append(tr2id_map[ranking[i]])\n",
    "        i+=1\n",
    "    while(len(pred) < 5):\n",
    "        pred.append(0)\n",
    "    predictions[pl_id] = np.array(pred)\n",
    "\n",
    "pred = pd.DataFrame()\n",
    "pred['playlist_id'] = predictions.keys()\n",
    "pred['track_ids'] = list(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl2id_map = build_num_to_id_map(playlists, 'playlist_id')\n",
    "tr2id_map = build_num_to_id_map(tracks, 'track_id')\n",
    "pl2num_map = build_id_to_num_map(playlists, 'playlist_id')\n",
    "\n",
    "M = M.tocsr()\n",
    "predictions = {}\n",
    "for pl_id in target_playlists['playlist_id'].values:\n",
    "    pl_num = pl2num_map[pl_id]\n",
    "    p1 = get_pred(M, S2, pl_num)\n",
    "    p2 = get_pred(M, S2, W_sparse[:,pl_num].argmax(), shrink=0.1)\n",
    "    \n",
    "    #print(\"{} {} {} {}\".format(p1[0], p2[0], np.intersect1d(p1[0], p2[0]), test[test['playlist_id'] == pl_id]['track_id'].values))\n",
    "    \n",
    "    predictions[pl_id] = blend([p1,p2])\n",
    "\n",
    "pred = pd.DataFrame()\n",
    "pred['playlist_id'] = predictions.keys()\n",
    "pred['track_ids'] = list(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050135354220864944\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05861101685329726\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08233683972401369\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blend(predictions):\n",
    "    preds = predictions[0][0]\n",
    "    vals = predictions[0][1]\n",
    "    \n",
    "    for i,p in enumerate(predictions[1][0]):\n",
    "        if p in preds:\n",
    "            idx, = np.where(preds==p)[0]\n",
    "            vals[idx] *= (1 + 1/(i+1))**2\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    vals = np.array(vals)\n",
    "    \n",
    "    \n",
    "    idx = vals.argsort()\n",
    "    idx = np.flip(idx, 0)\n",
    "    return preds[idx[:5]]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred(URM, SIM, pl_num, shrink=1):\n",
    "    global tr2id_map, tracks_in_playlist\n",
    "    r = URM[pl_num,:].dot(SIM)\n",
    "    idx = r.data.argsort()\n",
    "    ranking = np.flip(r.indices[idx], 0)\n",
    "    \n",
    "    values = []\n",
    "    count = 0\n",
    "    i = 0\n",
    "    pred = []\n",
    "    while count < 10 and i < len(ranking):\n",
    "        tr_id = tr2id_map[ranking[i]]\n",
    "        if tr_id not in tracks_in_playlist.loc[pl_id]['track_ids']:\n",
    "            pred.append(tr_id)\n",
    "            values.append(r[:,ranking[i]].data[0])\n",
    "            count +=1\n",
    "        i+=1\n",
    "    i=0\n",
    "    if (len(pred) < 5):\n",
    "        print(\"aaaargh len < 5\")\n",
    "        print(\"{0}\".format(pl_num))\n",
    "    while len(pred) < 5 and i < len(ranking):\n",
    "        pred.append(tr2id_map[ranking[i]])\n",
    "        values.append(r[:,ranking[i]].data[0])\n",
    "        i+=1\n",
    "    while(len(pred) < 5):\n",
    "        pred.append(0)\n",
    "        values.append(0)\n",
    "    return (np.array(pred), np.array(values)*shrink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S2[S2>5] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred['track_ids'] = pred['track_ids'].apply(lambda x : ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv(os.path.join(location,'results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction #2: min distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result so far: \n",
    "\n",
    "- 1.5 0.7 0 0 0.1 0 0.01 --> 0.06\n",
    "- 1.5 0.7 0 0 0.1 0 0 --> 0.0631\n",
    "- 1 0.7 0.01 0 0.3 0 0 --> 0.0628\n",
    "- 1.4 0.7 0.01 0 0.3 0 0.5 --> 0.0639\n",
    "- 1.4 0.7 0.01 0 0.3 0.4 0.01 --> 0.0589\n",
    "- 1.5 0.7 0 0 0.1 0 0 --> 0.06317\n",
    "- 1.5 0.7 0 0 0.1 0 0.02 --> 0.0644\n",
    "- 1.5 0.7 0 0 0.1 0 0.1 --> 0.6441\n",
    "- 1.7 0.7 0 0 0.1 0 0.5 --> 0.6509\n",
    "\n",
    "== dataset 2\n",
    "\n",
    "- 1.5 0.7 0.1 0 0.1 0 0.01 --> 0.0632\n",
    "\n",
    "(restoring tag idf)\n",
    "- 1.5 0.7 0.1 0 0.1 0 0.01 --> 0.06777\n",
    "- 1.5 0.7 0 0 0.3 0 0.01 --> 0.0677\n",
    "- 1.5 0.5 0.01 0.01 0.1 0 0.01 --> 0.06784\n",
    "\n",
    "(using tag IDF log(100000/#tag_freq)\n",
    "\n",
    "== dataset 5\n",
    "- 1.5 0.7 0.1 0.1 0.1 0.1 0.1 --> 0.0704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = load_similarity(location)\n",
    "S2 = S.copy()\n",
    "S2 = S2.transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl2id_map = build_num_to_id_map(playlists, 'playlist_id')\n",
    "tr2id_map = build_num_to_id_map(tracks, 'track_id')\n",
    "pl2num_map = build_id_to_num_map(playlists, 'playlist_id')\n",
    "\n",
    "M = M.tocsr()\n",
    "predictions = {}\n",
    "for pl_id in target_playlists['playlist_id'].values:\n",
    "    pl_num = pl2num_map[pl_id]\n",
    "    \n",
    "    tmp_a = M[pl_num,:].nonzero()[1]\n",
    "    tmp_c = S2[tmp_a,:]\n",
    "    tmp_b = tmp_c.data.argsort()\n",
    "    ranking = np.flip(tmp_c.indices[tmp_b], 0)\n",
    "    \n",
    "    count = 0\n",
    "    i = 0\n",
    "    pred = []\n",
    "    while count < 5 and i < len(ranking):\n",
    "        tr_id = tr2id_map[ranking[i]]\n",
    "        if tr_id not in tracks_in_playlist.loc[pl_id]['track_ids']:\n",
    "            pred.append(tr_id)\n",
    "            count +=1\n",
    "        i+=1\n",
    "    i=0\n",
    "    if (len(pred) < 5):\n",
    "        print(\"aaaargh len < 5\")\n",
    "        print(\"{0}\".format(pl_num))\n",
    "    while len(pred) < 5:\n",
    "        pred.append(0)\n",
    "        i+=1\n",
    "    predictions[pl_id] = np.array(pred)\n",
    "pred = pd.DataFrame()\n",
    "pred['playlist_id'] = predictions.keys()\n",
    "pred['track_ids'] = list(predictions.values())\n",
    "evaluate(test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.06932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabio part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_train(train, to_keep=0.8):\n",
    "    # shuffle train index\n",
    "    train.drop(range(int(len(train)*to_keep))).head()\n",
    "    \n",
    "#train = reduce_train(train, to_keep=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = 'test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_things(location, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_num = pd.DataFrame(tracks, copy=True)\n",
    "tracks_num['track_id_tmp'] = tracks['track_id']\n",
    "tracks_num['track_id'] = np.arange(len(tracks))\n",
    "\n",
    "playlists_num = pd.DataFrame(playlists, copy=True)\n",
    "playlists_num['playlist_id_tmp'] = playlists['playlist_id']\n",
    "playlists_num['playlist_id'] = np.arange(len(playlists))\n",
    "\n",
    "train_num = pd.DataFrame(train, copy=True)\n",
    "train_num['playlist_id_tmp'] = train['playlist_id']\n",
    "train_num['track_id_tmp'] = train['track_id']\n",
    "\n",
    "\n",
    "track_to_num = build_id_to_num_map(tracks, 'track_id')\n",
    "playlist_to_num = build_id_to_num_map(playlists, 'playlist_id')\n",
    "num_to_tracks = build_num_to_id_map(tracks, 'track_id')\n",
    "\n",
    "\n",
    "train_num['track_id'] = train['track_id'].apply(lambda x : track_to_num[x])\n",
    "train_num['playlist_id'] = train['playlist_id'].apply(lambda x : playlist_to_num[x])\n",
    "\n",
    "tracks_num.tags = tracks_num.tags.apply(lambda s: np.array(eval(s), dtype=int))\n",
    "playlists_num.title = playlists_num.title.apply(lambda s: np.array(eval(s), dtype=int))\n",
    "\n",
    "target_playlists_num = pd.DataFrame()\n",
    "target_playlists_num['playlist_id_tmp'] = target_playlists['playlist_id']\n",
    "target_playlists_num['playlist_id'] = target_playlists['playlist_id'].apply(lambda x : playlist_to_num[x])\n",
    "\n",
    "target_tracks_num = pd.DataFrame()\n",
    "target_tracks_num['track_id_tmp'] = target_tracks['track_id']\n",
    "target_tracks_num['track_id'] = target_tracks['track_id'].apply(lambda x : track_to_num[x])\n",
    "\n",
    "playlist_tracks = pd.DataFrame(train_num['playlist_id'].drop_duplicates())\n",
    "playlist_tracks.index = train_num['playlist_id'].unique()\n",
    "playlist_tracks['track_ids'] = train_num.groupby('playlist_id').apply(lambda x : x['track_id'].values)\n",
    "playlist_tracks = playlist_tracks.sort_values('playlist_id')\n",
    "\n",
    "track_playlists = pd.DataFrame(train_num['track_id'].drop_duplicates())\n",
    "track_playlists.index = train_num['track_id'].unique()\n",
    "track_playlists['playlist_ids'] = train_num.groupby('track_id').apply(lambda x : x['playlist_id'].values)\n",
    "track_playlists = track_playlists.sort_values('track_id')\n",
    "\n",
    "def transform_album_1(alb):\n",
    "    ar = eval(alb)\n",
    "    if len(ar) == 0 or (len(ar) > 0 and ar[0] == None):\n",
    "        ar = [-1]\n",
    "    return ar[0]\n",
    "\n",
    "def transform_album_2(alb):\n",
    "    global next_album_id\n",
    "    if alb == -1:\n",
    "        alb = next_album_id\n",
    "        next_album_id += 1\n",
    "    return alb\n",
    "    \n",
    "tracks_num.album = tracks_num.album.apply(lambda alb: transform_album_1(alb))\n",
    "\n",
    "last_album = tracks_num.album.max()\n",
    "next_album_id = last_album + 1\n",
    "\n",
    "tracks_num.album = tracks_num.album.apply(lambda alb: transform_album_2(alb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Rating Matrix URM\n",
    "def get_URM(tracks, playlists, playlist_tracks, track_playlists, normalized=False):\n",
    "    URM = lil_matrix((len(playlists), len(tracks)))\n",
    "    num_playlists = len(playlist_tracks)\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for row in track_playlists.itertuples():\n",
    "        track_id = row.track_id\n",
    "        #row.playlist_ids.sort()\n",
    "        nq = len(row.playlist_ids)\n",
    "        for pl_id in row.playlist_ids:\n",
    "            URM[pl_id,track_id] = math.log((num_playlists - nq + 0.5)/(nq + 0.5)) if normalized else 1\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    \n",
    "    return URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "URM = get_URM(tracks_num, playlists_num, playlist_tracks, track_playlists, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count distinct title tokens\n",
    "token_playlists = {}\n",
    "for row in playlists_num.itertuples():\n",
    "    for token in row.title:\n",
    "        if token in token_playlists:\n",
    "            token_playlists[token].append(row.playlist_id)\n",
    "        else:\n",
    "            token_playlists[token] = [row.playlist_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Title Matrix UTM\n",
    "def get_UTM(playlists, token_playlists, normalized=False):\n",
    "    unique_tokens = list(token_playlists.keys())\n",
    "    UTM = lil_matrix((len(playlists), max(unique_tokens)+1))\n",
    "    \n",
    "    num_playlists = len(playlists)\n",
    "    i = 0\n",
    "    \n",
    "    for token,playlist_ids in token_playlists.items():\n",
    "        nq = len(playlist_ids)\n",
    "        for playlist_id in playlist_ids:\n",
    "            UTM[playlist_id,token] = math.log((num_playlists - nq + 0.5)/(nq + 0.5)) if normalized else 1\n",
    "        if i % 2000 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "    \n",
    "    return UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UTM = get_UTM(playlists_num, token_playlists, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UTM = UTM.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = UTM.dot(UTM.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "def check_matrix(X, format='csc', dtype=np.float32):\n",
    "    if format == 'csc' and not isinstance(X, sps.csc_matrix):\n",
    "        return X.tocsc().astype(dtype)\n",
    "    elif format == 'csr' and not isinstance(X, sps.csr_matrix):\n",
    "        return X.tocsr().astype(dtype)\n",
    "    elif format == 'coo' and not isinstance(X, sps.coo_matrix):\n",
    "        return X.tocoo().astype(dtype)\n",
    "    elif format == 'dok' and not isinstance(X, sps.dok_matrix):\n",
    "        return X.todok().astype(dtype)\n",
    "    elif format == 'bsr' and not isinstance(X, sps.bsr_matrix):\n",
    "        return X.tobsr().astype(dtype)\n",
    "    elif format == 'dia' and not isinstance(X, sps.dia_matrix):\n",
    "        return X.todia().astype(dtype)\n",
    "    elif format == 'lil' and not isinstance(X, sps.lil_matrix):\n",
    "        return X.tolil().astype(dtype)\n",
    "    else:\n",
    "        return X.astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "class ISimilarity(object):\n",
    "    \"\"\"Abstract interface for the similarity metrics\"\"\"\n",
    "\n",
    "    def __init__(self, shrinkage=10):\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def compute(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Cosine(ISimilarity):\n",
    "    def compute(self, X):\n",
    "        # convert to csc matrix for faster column-wise operations\n",
    "        X = check_matrix(X, 'csc', dtype=np.float32)\n",
    "\n",
    "        # 1) normalize the columns in X\n",
    "        # compute the column-wise norm\n",
    "        # NOTE: this is slightly inefficient. We must copy X to compute the column norms.\n",
    "        # A faster solution is to  normalize the matrix inplace with a Cython function.\n",
    "        Xsq = X.copy()\n",
    "        Xsq.data **= 2\n",
    "        norm = np.sqrt(Xsq.sum(axis=0))\n",
    "        norm = np.asarray(norm).ravel()\n",
    "        norm += 1e-6\n",
    "        # compute the number of non-zeros in each column\n",
    "        # NOTE: this works only if X is instance of sparse.csc_matrix\n",
    "        col_nnz = np.diff(X.indptr)\n",
    "        # then normalize the values in each column\n",
    "        X.data /= np.repeat(norm, col_nnz)\n",
    "        print(\"Normalized\")\n",
    "\n",
    "        # 2) compute the cosine similarity using the dot-product\n",
    "        dist = X * X.T\n",
    "        print(\"Computed\")\n",
    "        \n",
    "        # zero out diagonal values\n",
    "        dist = dist - sps.dia_matrix((dist.diagonal()[scipy.newaxis, :], [0]), shape=dist.shape)\n",
    "        print(\"Removed diagonal\")\n",
    "        \n",
    "        # and apply the shrinkage\n",
    "        if self.shrinkage > 0:\n",
    "            dist = self.apply_shrinkage(X, dist)\n",
    "            print(\"Applied shrinkage\")    \n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def apply_shrinkage(self, X, dist):\n",
    "        # create an \"indicator\" version of X (i.e. replace values in X with ones)\n",
    "        X_ind = X.copy()\n",
    "        X_ind.data = np.ones_like(X_ind.data)\n",
    "        # compute the co-rated counts\n",
    "        co_counts = X_ind * X_ind.T\n",
    "        # remove the diagonal\n",
    "        co_counts = co_counts - sps.dia_matrix((co_counts.diagonal()[scipy.newaxis, :], [0]), shape=co_counts.shape)\n",
    "        # compute the shrinkage factor as co_counts_ij / (co_counts_ij + shrinkage)\n",
    "        # then multiply dist with it\n",
    "        co_counts_shrink = co_counts.copy()\n",
    "        co_counts_shrink.data += self.shrinkage\n",
    "        co_counts.data /= co_counts_shrink.data\n",
    "        dist.data *= co_counts.data\n",
    "        return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = Cosine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIM = distance.compute(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "SIM = check_matrix(SIM, 'csr')\n",
    "values, rows, cols = [], [], []\n",
    "nitems = SIM.shape[0]\n",
    "for i in range(nitems):\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Item %d of %d\" % (i, nitems))\n",
    "\n",
    "    this_item_weights = SIM[i,:].toarray()[0]\n",
    "    top_k_idx = np.argsort(this_item_weights) [-k:]\n",
    "\n",
    "    values.extend(this_item_weights[top_k_idx])\n",
    "    rows.extend(np.arange(nitems)[top_k_idx])\n",
    "    cols.extend(np.ones(k) * i)\n",
    "W_sparse = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WM = W_sparse.dot(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WM.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_sparse.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WM.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_sparse[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M[0,:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WM = WM + M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = Cosine(5)\n",
    "pl_weights = distance.compute(UTM)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl_weights[3,:].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "pl_weights = check_matrix(pl_weights, 'csr')\n",
    "values, rows, cols = [], [], []\n",
    "nitems = pl_weights.shape[0]\n",
    "for i in range(nitems):\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Item %d of %d\" % (i, nitems))\n",
    "\n",
    "    this_item_weights = pl_weights[i,:].toarray()[0]\n",
    "    top_k_idx = np.argsort(this_item_weights) [-k:]\n",
    "\n",
    "    values.extend(this_item_weights[top_k_idx])\n",
    "    rows.extend(np.arange(nitems)[top_k_idx])\n",
    "    cols.extend(np.ones(k) * i)\n",
    "W_sparse = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M2 = 1.0*URM>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M2 = M2.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URM2 = W_sparse.dot(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "URM2 = check_matrix(URM2, 'csr')\n",
    "values, rows, cols = [], [], []\n",
    "nitems = URM2.shape[0]\n",
    "for i in range(nitems):\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Item %d of %d\" % (i, nitems))\n",
    "\n",
    "    this_item_weights = URM2[i,:].toarray()[0]\n",
    "    top_k_idx = np.argsort(this_item_weights) [-k:]\n",
    "\n",
    "    values.extend(this_item_weights[top_k_idx])\n",
    "    rows.extend(np.arange(nitems)[top_k_idx])\n",
    "    cols.extend(np.ones(k) * i)\n",
    "URM2 = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URM3 = URM2 + M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1007372 + 3439780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = URM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M2 = M.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M2 = M2.transpose().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = Cosine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = dist.compute(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S2 = S.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 100\n",
    "S2 = check_matrix(S2, 'csr')\n",
    "values, rows, cols = [], [], []\n",
    "nitems = S2.shape[0]\n",
    "for i in range(nitems):\n",
    "    if (i % 10000 == 0):\n",
    "        print(\"Item %d of %d\" % (i, nitems))\n",
    "\n",
    "    this_item_weights = S2[i,:].toarray()[0]\n",
    "    top_k_idx = np.argsort(this_item_weights) [-k:]\n",
    "\n",
    "    values.extend(this_item_weights[top_k_idx])\n",
    "    rows.extend(np.arange(nitems)[top_k_idx])\n",
    "    cols.extend(np.ones(k) * i)\n",
    "\n",
    "S2 = sps.csc_matrix((values, (rows, cols)), shape=(nitems, nitems), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pd.read_csv('data/train_final.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttracks = pd.read_csv('data/target_tracks.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('data/tracks_final.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_final.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks['album_clear'] = tracks['album'].apply(clear_album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks['tags_clear'] = tracks['tags'].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks['tag_len'] = tracks['tags_clear'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_playlist_table = train.groupby('track_id').apply(lambda x : x['playlist_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_playlist_table = pd.DataFrame(track_playlist_table, columns=['playlist_ids'])\n",
    "track_playlist_table['track_id'] = track_playlist_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_playlist_table['pl_len'] = track_playlist_table['playlist_ids'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track_playlist_table['pl_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks['tag_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(tracks['tag_len']== 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(tracks['album_clear'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tttracks = tracks[tracks.track_id.isin(ttracks.track_id)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(tttracks['tag_len'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "758/32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2789/100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All target tracks has author\n",
    "\n",
    "8k over 32k tracks has null album, but this is ok according to general distribution (25% of tracks has no album)\n",
    "\n",
    "758 tracks has no tag, but this is normal according to distribution (2% of the tracks has empty tag list)\n",
    "all the tracks that has empty tag list also have empty duration and empty playcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_album(album_string):\n",
    "    l = album_string[1:-1]\n",
    "    if l == '' or l == 'None':\n",
    "        return None\n",
    "    else:\n",
    "        return int(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tttracks['album_clear'] = tttracks['album'].apply(clear_album)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(tttracks['duration'] == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('data/train_final.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, target_playlists, target_tracks = train_test_split(train, test_size = 0.4, min_playlist_tracks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import myslim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = load_URM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=1000, regularization=20, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M2 = bm25_weight(M) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 54s, sys: 5.09 s, total: 25min 59s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = model.user_factors\n",
    "B = model.item_factors.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.39558308e-02,  -1.95136739e-02,  -1.76010853e-02, ...,\n",
       "          7.36070611e-02,  -9.32374380e-02,   3.87374211e-03],\n",
       "       [  5.62223834e-03,   4.85316263e-02,   5.33056272e-02, ...,\n",
       "         -3.70495166e-02,  -6.44920694e-02,   1.75007464e-02],\n",
       "       [  2.54160481e-01,   4.20323031e-02,  -1.12126596e-01, ...,\n",
       "         -5.14525263e-01,   1.81423750e-01,   1.95108441e-01],\n",
       "       ..., \n",
       "       [  5.35816987e-03,   8.20083728e-05,   5.26052803e-03, ...,\n",
       "          2.66011701e-03,   3.64891299e-03,  -1.38462019e-03],\n",
       "       [ -1.22917066e-02,   1.84405874e-02,  -1.72647293e-03, ...,\n",
       "         -3.67257242e-02,   8.14163426e-03,   3.30671501e-02],\n",
       "       [  1.96289677e-02,   1.49906338e-02,   1.37923555e-02, ...,\n",
       "          3.78335100e-02,   4.10645258e-02,  -4.39815721e-03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl2id_map = build_num_to_id_map(playlists, 'playlist_id')\n",
    "tr2id_map = build_num_to_id_map(tracks, 'track_id')\n",
    "pl2num_map = build_id_to_num_map(playlists, 'playlist_id')\n",
    "\n",
    "M = M.tocsr()\n",
    "predictions = {}\n",
    "for pl_id in target_playlists['playlist_id'].values:\n",
    "    pl_num = pl2num_map[pl_id]\n",
    "    r = A[pl_num,:].dot(B)\n",
    "    idx = r.argsort()\n",
    "    ranking = np.flip(idx, 0)\n",
    "    \n",
    "    count = 0\n",
    "    i = 0\n",
    "    pred = []\n",
    "    while count < 5 and i < len(ranking):\n",
    "        tr_id = tr2id_map[ranking[i]]\n",
    "        if tr_id not in tracks_in_playlist.loc[pl_id]['track_ids']:\n",
    "            pred.append(tr_id)\n",
    "            count +=1\n",
    "        i+=1\n",
    "    i=0\n",
    "    if (len(pred) < 5):\n",
    "        print(\"aaaargh len < 5\")\n",
    "        print(\"{0}\".format(pl_num))\n",
    "    while len(pred) < 5 and i < len(ranking):\n",
    "        pred.append(tr2id_map[ranking[i]])\n",
    "        i+=1\n",
    "    while(len(pred) < 5):\n",
    "        pred.append(0)\n",
    "    predictions[pl_id] = np.array(pred)\n",
    "\n",
    "pred = pd.DataFrame()\n",
    "pred['playlist_id'] = predictions.keys()\n",
    "pred['track_ids'] = list(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6966406515100106e-05\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
